{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 1 columns):\n",
      "norm_tokens_doc    1000 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\n",
    "    filepath_or_buffer='../../data/processed/hi_rws_0001_0256_processed.csv', \n",
    "    header=None, \n",
    "    names=['norm_tokens_doc'],\n",
    "    nrows=1000\n",
    ")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file fix\n",
    "from itertools import chain\n",
    "from ast import literal_eval\n",
    "df.norm_tokens_doc = df.norm_tokens_doc.apply(lambda x: literal_eval(x))\n",
    "df['norm_tokens'] = df.norm_tokens_doc.apply(lambda x: list(chain(*x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [stumble, great, restaurant, overlook, ocean, ...\n",
       "1    [excellent, view, ocean, sunset, excellent, fo...\n",
       "2    [place, what, review, portray, starter, walk, ...\n",
       "3    [excited, repeat, keoki, kauai, lovefest, part...\n",
       "4    [look, tourist, spot, could, tell, other, revi...\n",
       "Name: norm_tokens, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.norm_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(stumble, great, restaurant, overlook, ocean,...\n",
       "1    [(excellent, view, ocean, sunset), (excellent,...\n",
       "2    [(place, what, review, portray), (starter, wal...\n",
       "3    [(excited, repeat, keoki, kauai, lovefest, par...\n",
       "4    [(look, tourist, spot), (could, tell, other, r...\n",
       "Name: norm_tokens_doc, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.norm_tokens_doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 0.025\n",
      "iteration 1 0.0248\n",
      "iteration 2 0.0246\n",
      "iteration 3 0.0244\n",
      "iteration 4 0.0242\n",
      "iteration 5 0.024\n",
      "iteration 6 0.0238\n",
      "iteration 7 0.0236\n",
      "iteration 8 0.0234\n",
      "iteration 9 0.0232\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "docs = []\n",
    "for i, norm_token in enumerate(df.norm_tokens):\n",
    "    docs.append(TaggedDocument(norm_token, tags=[i]))\n",
    "    \n",
    "model = Doc2Vec(vector_size=8, window=5, min_count=5, workers=4, epochs=10)\n",
    "model.build_vocab(docs)\n",
    "\n",
    "for epoch in range(10):\n",
    "    print('iteration {0}'.format(epoch), round(model.alpha, 4))\n",
    "    model.train(docs,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=epoch)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0128735  -0.00175112 -0.14733122  0.04462452  0.10733464  0.211001\n",
      "  0.3709563  -0.06415744]\n",
      "[-0.02308503  0.09367393 -0.02145127  0.07479919  0.05140461  0.06081245\n",
      "  0.06499862  0.00950072]\n",
      "[-0.12083384  0.18723033 -0.36883876  0.02520585  0.3758736   0.31960443\n",
      "  0.78572774 -0.01358689]\n",
      "[-0.29434308  0.42585114 -0.28646222 -0.23193839  0.2992898   0.08091611\n",
      "  0.30105683 -0.1269898 ]\n",
      "[-0.1216435   0.3036373  -0.36133906  0.12667844  0.3099317   0.0971282\n",
      "  0.54056406 -0.17312063]\n",
      "[-0.05302937  0.18524486 -0.07554426  0.08786791  0.14252311  0.10472614\n",
      "  0.19809969 -0.00528354]\n",
      "[ 0.05424517  0.06343371 -0.04671352  0.08356301  0.09515156 -0.05661555\n",
      "  0.07675306  0.0018847 ]\n",
      "[-0.043973    0.12069135 -0.29421648  0.05756711  0.24247009  0.10671855\n",
      "  0.42696905 -0.06563081]\n",
      "[-0.17638639  0.16010065 -0.17442039 -0.09821399  0.08557218 -0.03781883\n",
      "  0.33034962  0.02741913]\n",
      "[-0.0757033   0.19272095 -0.27174577  0.12532946  0.28237864  0.04786527\n",
      "  0.53450465 -0.03863899]\n",
      "[-0.04818025  0.10074062 -0.10247719  0.06996887  0.116179    0.13807674\n",
      "  0.27614808 -0.03493499]\n",
      "[ 0.03374679  0.07408068 -0.17493777  0.11315447  0.05676082  0.07918329\n",
      "  0.2071385  -0.07541197]\n",
      "[-0.04104733  0.11667849 -0.32574645  0.06187889  0.21934493  0.05525185\n",
      "  0.33740103  0.0686339 ]\n",
      "[-0.26467386  0.32330483 -0.33013034  0.087212    0.3261199   0.09992685\n",
      "  0.59976864 -0.10393468]\n",
      "[-0.12085434  0.13466266 -0.10278963  0.07618189  0.14357172  0.11537962\n",
      "  0.27968052  0.03915485]\n",
      "[-0.06337935  0.12220708 -0.22093685  0.01158728  0.27093592  0.11916252\n",
      "  0.13762823  0.10280218]\n",
      "[-0.06265008  0.04576227 -0.08734684  0.10311509  0.07392599  0.08702163\n",
      "  0.19614929  0.06669984]\n",
      "[ 0.01604705  0.07161421 -0.18567419  0.11581532  0.18132345  0.05546732\n",
      "  0.19587499  0.00770845]\n",
      "[-0.25230005  0.2603438  -0.3839612   0.1823076   0.38600373  0.11926743\n",
      "  0.8260845  -0.0868055 ]\n",
      "[-0.09555425  0.10703648 -0.1472238   0.05552994  0.22917606  0.06688818\n",
      "  0.28850877 -0.02495087]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for norm_token in df.norm_tokens[:20]:\n",
    "    v = model.infer_vector(norm_token, alpha=model.alpha, steps=10)\n",
    "    X.append(v)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Doc2VecVocab' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-e93d9238f559>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Doc2VecVocab' object is not callable"
     ]
    }
   ],
   "source": [
    "model.vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(936, 0.9446977972984314),\n",
       " (675, 0.9426066875457764),\n",
       " (739, 0.931880533695221),\n",
       " (612, 0.9311423897743225),\n",
       " (556, 0.9275106191635132),\n",
       " (241, 0.9132927060127258),\n",
       " (847, 0.9102202653884888),\n",
       " (255, 0.9092434644699097),\n",
       " (158, 0.8943102955818176),\n",
       " (770, 0.8904882669448853)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.most_similar(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['excellent', 'view', 'ocean', 'sunset', 'excellent', 'food', 'have', 'fresh', 'fish', 'coconut', 'yuzu', 'husband', 'love', 'waitress', 'nice']\n",
      "['food', 'amazing', 'great', 'service', 'atmosphere', 'have', 'lobster', 'crust', 'fish', 'skewer', 'shrimp', 'pasta', 'table', 'everyone', 'love', 'food', 'would', 'recommend', 'place', 'would', 'come']\n"
     ]
    }
   ],
   "source": [
    "print(df.norm_tokens[1])\n",
    "print(df.norm_tokens[241])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 2, 3, 2, 1, 1, 0, 1, 2, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import Birch\n",
    " \n",
    "brc = Birch(branching_factor=50, n_clusters=5, threshold=0.1, compute_labels=True)\n",
    "brc.fit(X)\n",
    "brc.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 2, 3, 2, 1, 1, 0, 1, 2, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
