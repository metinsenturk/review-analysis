{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alias</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>dataPublished</th>\n",
       "      <th>description</th>\n",
       "      <th>author</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>chr_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_content</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_tokens_doc</th>\n",
       "      <th>norm_tokens_doc</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>norm_tokens</th>\n",
       "      <th>sent_topics</th>\n",
       "      <th>topic_mode</th>\n",
       "      <th>topic_list</th>\n",
       "      <th>svm_classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>I stumbled across this great restaurant overlo...</td>\n",
       "      <td>Bella L.</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>11</td>\n",
       "      <td>664</td>\n",
       "      <td>4.022222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674074</td>\n",
       "      <td>['I stumbled across this great restaurant over...</td>\n",
       "      <td>[('I', 'stumbled', 'across', 'this', 'great', ...</td>\n",
       "      <td>[('stumbl', 'across', 'great', 'restaur', 'ove...</td>\n",
       "      <td>['I', 'stumbled', 'across', 'this', 'great', '...</td>\n",
       "      <td>['stumbl', 'across', 'great', 'restaur', 'over...</td>\n",
       "      <td>[(5, 0.181669682264328), (2, 0.186504259705543...</td>\n",
       "      <td>1</td>\n",
       "      <td>5,2,1,3,6,3,2,0,6,1,5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>Excellent view on the ocean at sunset.\\nExcell...</td>\n",
       "      <td>Rachou A.</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>160</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>['Excellent view on the ocean at sunset.', 'Ex...</td>\n",
       "      <td>[('Excellent', 'view', 'on', 'the', 'ocean', '...</td>\n",
       "      <td>[('excel', 'view', 'ocean', 'sunset'), ('excel...</td>\n",
       "      <td>['Excellent', 'view', 'on', 'the', 'ocean', 'a...</td>\n",
       "      <td>['excel', 'view', 'ocean', 'sunset', 'excel', ...</td>\n",
       "      <td>[(6, 0.146974578499794), (3, 0.139927998185157...</td>\n",
       "      <td>6</td>\n",
       "      <td>6,3,8,6,9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-12-25</td>\n",
       "      <td>This place was not what the reviews portrayed ...</td>\n",
       "      <td>Ozzetta B.</td>\n",
       "      <td>0</td>\n",
       "      <td>275</td>\n",
       "      <td>14</td>\n",
       "      <td>1229</td>\n",
       "      <td>3.596364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567273</td>\n",
       "      <td>['This place was not what the reviews portraye...</td>\n",
       "      <td>[('This', 'place', 'was', 'not', 'what', 'the'...</td>\n",
       "      <td>[('place', 'review', 'portray'), ('starter', '...</td>\n",
       "      <td>['This', 'place', 'was', 'not', 'what', 'the',...</td>\n",
       "      <td>['place', 'review', 'portray', 'starter', 'wal...</td>\n",
       "      <td>[(6, 0.15684203803539276), (8, 0.2266744673252...</td>\n",
       "      <td>8</td>\n",
       "      <td>6,8,2,5,4,8,3,9,8,8,8,1,7,6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-08</td>\n",
       "      <td>We were excited to repeat our Keoki's (in Kaua...</td>\n",
       "      <td>Arleen C.</td>\n",
       "      <td>0</td>\n",
       "      <td>475</td>\n",
       "      <td>34</td>\n",
       "      <td>2226</td>\n",
       "      <td>3.783158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604211</td>\n",
       "      <td>[\"We were excited to repeat our Keoki's (in Ka...</td>\n",
       "      <td>[('We', 'were', 'excited', 'to', 'repeat', 'ou...</td>\n",
       "      <td>[('excit', 'repeat', 'keoki', \"'s\", 'kauai', '...</td>\n",
       "      <td>['We', 'were', 'excited', 'to', 'repeat', 'our...</td>\n",
       "      <td>['excit', 'repeat', 'keoki', \"'s\", 'kauai', 'l...</td>\n",
       "      <td>[(2, 0.1735130101442337), (4, 0.13328838348388...</td>\n",
       "      <td>2</td>\n",
       "      <td>2,4,9,0,5,3,7,1,0,4,0,5,5,8,6,9,2,8,6,2,2,1,6,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>If you're looking for a tourist spot, this is ...</td>\n",
       "      <td>Carol B.</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>10</td>\n",
       "      <td>776</td>\n",
       "      <td>3.732143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636905</td>\n",
       "      <td>[\"If you're looking for a tourist spot, this i...</td>\n",
       "      <td>[('If', 'you', \"'re\", 'looking', 'for', 'a', '...</td>\n",
       "      <td>[(\"'re\", 'look', 'tourist', 'spot'), ('unfortu...</td>\n",
       "      <td>['If', 'you', \"'re\", 'looking', 'for', 'a', 't...</td>\n",
       "      <td>[\"'re\", 'look', 'tourist', 'spot', 'unfortun',...</td>\n",
       "      <td>[(6, 0.1469745934009552), (9, 0.20430350303649...</td>\n",
       "      <td>6</td>\n",
       "      <td>6,9,8,6,4,0,5,3,1,9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                alias  ratingValue dataPublished  \\\n",
       "0  kimos-maui-lahaina            5    2019-01-06   \n",
       "1  kimos-maui-lahaina            5    2019-01-04   \n",
       "2  kimos-maui-lahaina            3    2018-12-25   \n",
       "3  kimos-maui-lahaina            2    2018-12-08   \n",
       "4  kimos-maui-lahaina            3    2018-11-29   \n",
       "\n",
       "                                         description      author  sentiment  \\\n",
       "0  I stumbled across this great restaurant overlo...    Bella L.          1   \n",
       "1  Excellent view on the ocean at sunset.\\nExcell...   Rachou A.          1   \n",
       "2  This place was not what the reviews portrayed ...  Ozzetta B.          0   \n",
       "3  We were excited to repeat our Keoki's (in Kaua...   Arleen C.          0   \n",
       "4  If you're looking for a tourist spot, this is ...    Carol B.          0   \n",
       "\n",
       "   word_count  sent_count  chr_count  avg_word_len       ...        \\\n",
       "0         135          11        664      4.022222       ...         \n",
       "1          36           5        160      3.611111       ...         \n",
       "2         275          14       1229      3.596364       ...         \n",
       "3         475          34       2226      3.783158       ...         \n",
       "4         168          10        776      3.732143       ...         \n",
       "\n",
       "   ratio_content                                        sent_tokens  \\\n",
       "0       0.674074  ['I stumbled across this great restaurant over...   \n",
       "1       0.638889  ['Excellent view on the ocean at sunset.', 'Ex...   \n",
       "2       0.567273  ['This place was not what the reviews portraye...   \n",
       "3       0.604211  [\"We were excited to repeat our Keoki's (in Ka...   \n",
       "4       0.636905  [\"If you're looking for a tourist spot, this i...   \n",
       "\n",
       "                                     word_tokens_doc  \\\n",
       "0  [('I', 'stumbled', 'across', 'this', 'great', ...   \n",
       "1  [('Excellent', 'view', 'on', 'the', 'ocean', '...   \n",
       "2  [('This', 'place', 'was', 'not', 'what', 'the'...   \n",
       "3  [('We', 'were', 'excited', 'to', 'repeat', 'ou...   \n",
       "4  [('If', 'you', \"'re\", 'looking', 'for', 'a', '...   \n",
       "\n",
       "                                     norm_tokens_doc  \\\n",
       "0  [('stumbl', 'across', 'great', 'restaur', 'ove...   \n",
       "1  [('excel', 'view', 'ocean', 'sunset'), ('excel...   \n",
       "2  [('place', 'review', 'portray'), ('starter', '...   \n",
       "3  [('excit', 'repeat', 'keoki', \"'s\", 'kauai', '...   \n",
       "4  [(\"'re\", 'look', 'tourist', 'spot'), ('unfortu...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  ['I', 'stumbled', 'across', 'this', 'great', '...   \n",
       "1  ['Excellent', 'view', 'on', 'the', 'ocean', 'a...   \n",
       "2  ['This', 'place', 'was', 'not', 'what', 'the',...   \n",
       "3  ['We', 'were', 'excited', 'to', 'repeat', 'our...   \n",
       "4  ['If', 'you', \"'re\", 'looking', 'for', 'a', 't...   \n",
       "\n",
       "                                         norm_tokens  \\\n",
       "0  ['stumbl', 'across', 'great', 'restaur', 'over...   \n",
       "1  ['excel', 'view', 'ocean', 'sunset', 'excel', ...   \n",
       "2  ['place', 'review', 'portray', 'starter', 'wal...   \n",
       "3  ['excit', 'repeat', 'keoki', \"'s\", 'kauai', 'l...   \n",
       "4  [\"'re\", 'look', 'tourist', 'spot', 'unfortun',...   \n",
       "\n",
       "                                         sent_topics  topic_mode  \\\n",
       "0  [(5, 0.181669682264328), (2, 0.186504259705543...           1   \n",
       "1  [(6, 0.146974578499794), (3, 0.139927998185157...           6   \n",
       "2  [(6, 0.15684203803539276), (8, 0.2266744673252...           8   \n",
       "3  [(2, 0.1735130101442337), (4, 0.13328838348388...           2   \n",
       "4  [(6, 0.1469745934009552), (9, 0.20430350303649...           6   \n",
       "\n",
       "                                          topic_list  svm_classifier  \n",
       "0                              5,2,1,3,6,3,2,0,6,1,5               1  \n",
       "1                                          6,3,8,6,9               1  \n",
       "2                        6,8,2,5,4,8,3,9,8,8,8,1,7,6               0  \n",
       "3  2,4,9,0,5,3,7,1,0,4,0,5,5,8,6,9,2,8,6,2,2,1,6,...               1  \n",
       "4                                6,9,8,6,4,0,5,3,1,9               1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"../../data/processed/yp_competitors_rws_0001_0050_complete.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a3c10c4e0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.ratingValue.plot('hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('came', 'back', 'kimo', \"'s\", 'disappoint', 'find', 'longer', 'lobster', 'slider', 'truffl', 'chip', 'happi', 'hour', 'menu'), (\"'s\", 'pretti', 'much', 'sister', 'would', 'alway', 'go', 'visit', 'maui'), ('waitress', 'said', 'replac', 'menu', 'option', 'buffalo', 'chicken', 'bite'), ('order', \"n't\", 'anyth', 'special', 'world'), ('typic', \"'d\", 'get', 'place'), ('also', 'got', 'macadamia', 'crust', 'calamari', '...', '.still', \"n't\", 'get', 'macadamia', 'part'), ('also', 'order', 'avocado', 'poke', 'stack'), ('poke', \"n't\", 'realli', 'cold'), (\"n't\", 'like', 'poke', \"n't\", 'cold'), ('sister', 'get', 'cheeseburg', 'time'), ('huge', 'looked/smel', 'realli', 'good'), ('could', \"n't\", 'even', 'finish'), ('said', 'juici', 'tasti'), ('place', 'nice', 'ocean-front', 'spot'), ('pretti', 'pricey', 'though'), ('went', 'cafe', 'lei', 'dune', 'bill', 'came', 'significantli', 'le', 'even', 'though', 'order', \"'ve\", 'left', 'review', 'photo', 'order', 'see'), ('unless', 'bring', 'back', 'lobster', 'slider', \"'s\", 'realli', 'noth', 'would', 'call', 'come', 'back')]\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[95, :].norm_tokens_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_tokens_doc</th>\n",
       "      <th>norm_tokens_doc</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>norm_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[I stumbled across this great restaurant overl...</td>\n",
       "      <td>[(I, stumbled, across, this, great, restaurant...</td>\n",
       "      <td>[(stumbl, across, great, restaur, overlook, oc...</td>\n",
       "      <td>[I, stumbled, across, this, great, restaurant,...</td>\n",
       "      <td>[stumbl, across, great, restaur, overlook, oce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Excellent view on the ocean at sunset., Excel...</td>\n",
       "      <td>[(Excellent, view, on, the, ocean, at, sunset,...</td>\n",
       "      <td>[(excel, view, ocean, sunset), (excel, food), ...</td>\n",
       "      <td>[Excellent, view, on, the, ocean, at, sunset, ...</td>\n",
       "      <td>[excel, view, ocean, sunset, excel, food, fres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[This place was not what the reviews portrayed...</td>\n",
       "      <td>[(This, place, was, not, what, the, reviews, p...</td>\n",
       "      <td>[(place, review, portray), (starter, walk, sta...</td>\n",
       "      <td>[This, place, was, not, what, the, reviews, po...</td>\n",
       "      <td>[place, review, portray, starter, walk, stair,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[We were excited to repeat our Keoki's (in Kau...</td>\n",
       "      <td>[(We, were, excited, to, repeat, our, Keoki, '...</td>\n",
       "      <td>[(excit, repeat, keoki, 's, kauai, lovefest, s...</td>\n",
       "      <td>[We, were, excited, to, repeat, our, Keoki, 's...</td>\n",
       "      <td>[excit, repeat, keoki, 's, kauai, lovefest, si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[If you're looking for a tourist spot, this is...</td>\n",
       "      <td>[(If, you, 're, looking, for, a, tourist, spot...</td>\n",
       "      <td>[('re, look, tourist, spot), (unfortun, could,...</td>\n",
       "      <td>[If, you, 're, looking, for, a, tourist, spot,...</td>\n",
       "      <td>['re, look, tourist, spot, unfortun, could, n'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[What an amazing restaurant, especially the vi...</td>\n",
       "      <td>[(What, an, amazing, restaurant, ,, especially...</td>\n",
       "      <td>[(amaz, restaur, especi, view, dinner), (dine,...</td>\n",
       "      <td>[What, an, amazing, restaurant, ,, especially,...</td>\n",
       "      <td>[amaz, restaur, especi, view, dinner, dine, wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sent_tokens  \\\n",
       "0  [I stumbled across this great restaurant overl...   \n",
       "1  [Excellent view on the ocean at sunset., Excel...   \n",
       "2  [This place was not what the reviews portrayed...   \n",
       "3  [We were excited to repeat our Keoki's (in Kau...   \n",
       "4  [If you're looking for a tourist spot, this is...   \n",
       "5  [What an amazing restaurant, especially the vi...   \n",
       "\n",
       "                                     word_tokens_doc  \\\n",
       "0  [(I, stumbled, across, this, great, restaurant...   \n",
       "1  [(Excellent, view, on, the, ocean, at, sunset,...   \n",
       "2  [(This, place, was, not, what, the, reviews, p...   \n",
       "3  [(We, were, excited, to, repeat, our, Keoki, '...   \n",
       "4  [(If, you, 're, looking, for, a, tourist, spot...   \n",
       "5  [(What, an, amazing, restaurant, ,, especially...   \n",
       "\n",
       "                                     norm_tokens_doc  \\\n",
       "0  [(stumbl, across, great, restaur, overlook, oc...   \n",
       "1  [(excel, view, ocean, sunset), (excel, food), ...   \n",
       "2  [(place, review, portray), (starter, walk, sta...   \n",
       "3  [(excit, repeat, keoki, 's, kauai, lovefest, s...   \n",
       "4  [('re, look, tourist, spot), (unfortun, could,...   \n",
       "5  [(amaz, restaur, especi, view, dinner), (dine,...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  [I, stumbled, across, this, great, restaurant,...   \n",
       "1  [Excellent, view, on, the, ocean, at, sunset, ...   \n",
       "2  [This, place, was, not, what, the, reviews, po...   \n",
       "3  [We, were, excited, to, repeat, our, Keoki, 's...   \n",
       "4  [If, you, 're, looking, for, a, tourist, spot,...   \n",
       "5  [What, an, amazing, restaurant, ,, especially,...   \n",
       "\n",
       "                                         norm_tokens  \n",
       "0  [stumbl, across, great, restaur, overlook, oce...  \n",
       "1  [excel, view, ocean, sunset, excel, food, fres...  \n",
       "2  [place, review, portray, starter, walk, stair,...  \n",
       "3  [excit, repeat, keoki, 's, kauai, lovefest, si...  \n",
       "4  ['re, look, tourist, spot, unfortun, could, n'...  \n",
       "5  [amaz, restaur, especi, view, dinner, dine, wa...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix column type error\n",
    "from ast import literal_eval\n",
    "\n",
    "fix_columns_list = ['sent_tokens', 'word_tokens_doc', 'norm_tokens_doc', 'word_tokens', 'norm_tokens']\n",
    "for column in fix_columns_list:\n",
    "    df[column] = df[column].apply(lambda x: literal_eval(x))\n",
    "df.loc[:5, fix_columns_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document is Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136033 136033\n"
     ]
    }
   ],
   "source": [
    "# X is sents, y is sentiments that generated by doc(len(lists) * [sent]).\n",
    "X = list(chain(*df.sent_tokens))\n",
    "doc_sentiment = []\n",
    "for sentiment, sents in zip(df.sentiment, df.sent_tokens):\n",
    "    doc_sents_temp = [sentiment] * len(sents)\n",
    "    doc_sentiment.append(doc_sents_temp)\n",
    "y = list(chain(*doc_sentiment))\n",
    "print(len(X), len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I stumbled across this great restaurant overlooking the ocean for lunch during my vacation to Maui.',\n",
       " 'I did not have high expectations for this place, but boy did it blow me out of the water.',\n",
       " \"The fish and chips is some of the best I've ever had (and I've had lots, including from London).\",\n",
       " 'I highly recommend it.',\n",
       " 'Also, the turkey bacon sandwich was SO good.',\n",
       " 'In terms of drinks, I highly recommend the Pacific Paradise drink!',\n",
       " 'So delicious and tropical!',\n",
       " 'I also really enjoyed the Lahaina Lemonade.',\n",
       " 'Service was really great!',\n",
       " 'I wish I remembered the waitresses name because she was truly awesome and recommend the best stuff.',\n",
       " 'She was blonde and had cute sunglasses.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "df.sent_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<136033x21265 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 757696 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "sent_tokens_tfmd = cv.fit_transform(chain(*df.sent_tokens))\n",
    "sent_tokens_tfmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<136033x21265 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 757696 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "tfidf.fit_transform(sent_tokens_tfmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7477450324553601\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=10, tol=0.05)),\n",
    "])\n",
    "\n",
    "pipe.fit(X, y)\n",
    "predicted = pipe.predict(X)\n",
    "print(np.mean(predicted == y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Document is Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "X = df.norm_tokens_doc.apply(lambda x: ' '.join(chain(*x)))\n",
    "y = df.sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8818611987381704\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=100, max_iter=10, tol=0.05))])\n",
    "\n",
    "pipe.fit(X, y)\n",
    "sgd_pred = pipe.predict(X)\n",
    "print(np.mean(sgd_pred == y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8476866456361725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "pipe = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe.fit(X, y)\n",
    "mnb_pred = pipe.predict(X)\n",
    "print(np.mean(mnb_pred == y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.881861</td>\n",
       "      <td>0.873036</td>\n",
       "      <td>0.930098</td>\n",
       "      <td>0.995140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.847687</td>\n",
       "      <td>0.838706</td>\n",
       "      <td>0.912001</td>\n",
       "      <td>0.999334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  0.881861  0.873036  0.930098  0.995140\n",
       "1  0.847687  0.838706  0.912001  0.999334"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i in [sgd_pred, mnb_pred]:\n",
    "    acc = accuracy_score(y, i)\n",
    "    pre = precision_score(y, i)\n",
    "    flc = f1_score((y, i)\n",
    "    rec = recall_score(y, i, pos_label=1)\n",
    "    results.append((acc, pre, flc, rec))\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.46      0.62      3998\n",
      "           1       0.87      1.00      0.93     15022\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     19020\n",
      "   macro avg       0.92      0.73      0.77     19020\n",
      "weighted avg       0.89      0.88      0.86     19020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, classification_report\n",
    "\n",
    "print(classification_report(y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['svm_classifier'] = pd.Series(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alias</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>dataPublished</th>\n",
       "      <th>description</th>\n",
       "      <th>author</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>chr_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_content</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_tokens_doc</th>\n",
       "      <th>norm_tokens_doc</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>norm_tokens</th>\n",
       "      <th>sent_topics</th>\n",
       "      <th>topic_mode</th>\n",
       "      <th>topic_list</th>\n",
       "      <th>svm_classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>I stumbled across this great restaurant overlo...</td>\n",
       "      <td>Bella L.</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>11</td>\n",
       "      <td>664</td>\n",
       "      <td>4.022222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674074</td>\n",
       "      <td>[I stumbled across this great restaurant overl...</td>\n",
       "      <td>[(I, stumbled, across, this, great, restaurant...</td>\n",
       "      <td>[(stumbl, across, great, restaur, overlook, oc...</td>\n",
       "      <td>[I, stumbled, across, this, great, restaurant,...</td>\n",
       "      <td>[stumbl, across, great, restaur, overlook, oce...</td>\n",
       "      <td>[(5, 0.3112545907497406), (5, 0.20203207433223...</td>\n",
       "      <td>5</td>\n",
       "      <td>5,5,9,5,3,4,5,5,5,9,5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>Excellent view on the ocean at sunset.\\nExcell...</td>\n",
       "      <td>Rachou A.</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>160</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>[Excellent view on the ocean at sunset., Excel...</td>\n",
       "      <td>[(Excellent, view, on, the, ocean, at, sunset,...</td>\n",
       "      <td>[(excel, view, ocean, sunset), (excel, food), ...</td>\n",
       "      <td>[Excellent, view, on, the, ocean, at, sunset, ...</td>\n",
       "      <td>[excel, view, ocean, sunset, excel, food, fres...</td>\n",
       "      <td>[(5, 0.24188750982284546), (5, 0.1962578445672...</td>\n",
       "      <td>5</td>\n",
       "      <td>5,5,3,5,5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-12-25</td>\n",
       "      <td>This place was not what the reviews portrayed ...</td>\n",
       "      <td>Ozzetta B.</td>\n",
       "      <td>0</td>\n",
       "      <td>275</td>\n",
       "      <td>14</td>\n",
       "      <td>1229</td>\n",
       "      <td>3.596364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567273</td>\n",
       "      <td>[This place was not what the reviews portrayed...</td>\n",
       "      <td>[(This, place, was, not, what, the, reviews, p...</td>\n",
       "      <td>[(place, review, portray), (starter, walk, sta...</td>\n",
       "      <td>[This, place, was, not, what, the, reviews, po...</td>\n",
       "      <td>[place, review, portray, starter, walk, stair,...</td>\n",
       "      <td>[(5, 0.19056889414787292), (5, 0.2658553421497...</td>\n",
       "      <td>5</td>\n",
       "      <td>5,5,1,1,1,7,5,5,5,0,5,5,2,5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-08</td>\n",
       "      <td>We were excited to repeat our Keoki's (in Kaua...</td>\n",
       "      <td>Arleen C.</td>\n",
       "      <td>0</td>\n",
       "      <td>475</td>\n",
       "      <td>34</td>\n",
       "      <td>2226</td>\n",
       "      <td>3.783158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604211</td>\n",
       "      <td>[We were excited to repeat our Keoki's (in Kau...</td>\n",
       "      <td>[(We, were, excited, to, repeat, our, Keoki, '...</td>\n",
       "      <td>[(excit, repeat, keoki, 's, kauai, lovefest, s...</td>\n",
       "      <td>[We, were, excited, to, repeat, our, Keoki, 's...</td>\n",
       "      <td>[excit, repeat, keoki, 's, kauai, lovefest, si...</td>\n",
       "      <td>[(5, 0.18351130187511444), (5, 0.2023473381996...</td>\n",
       "      <td>5</td>\n",
       "      <td>5,5,2,6,5,0,5,5,8,5,5,5,7,7,5,5,5,5,5,5,5,7,9,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>If you're looking for a tourist spot, this is ...</td>\n",
       "      <td>Carol B.</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>10</td>\n",
       "      <td>776</td>\n",
       "      <td>3.732143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636905</td>\n",
       "      <td>[If you're looking for a tourist spot, this is...</td>\n",
       "      <td>[(If, you, 're, looking, for, a, tourist, spot...</td>\n",
       "      <td>[('re, look, tourist, spot), (unfortun, could,...</td>\n",
       "      <td>[If, you, 're, looking, for, a, tourist, spot,...</td>\n",
       "      <td>['re, look, tourist, spot, unfortun, could, n'...</td>\n",
       "      <td>[(5, 0.21350185573101044), (5, 0.1800063550472...</td>\n",
       "      <td>5</td>\n",
       "      <td>5,5,2,6,9,5,9,0,5,5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                alias  ratingValue dataPublished  \\\n",
       "0  kimos-maui-lahaina            5    2019-01-06   \n",
       "1  kimos-maui-lahaina            5    2019-01-04   \n",
       "2  kimos-maui-lahaina            3    2018-12-25   \n",
       "3  kimos-maui-lahaina            2    2018-12-08   \n",
       "4  kimos-maui-lahaina            3    2018-11-29   \n",
       "\n",
       "                                         description      author  sentiment  \\\n",
       "0  I stumbled across this great restaurant overlo...    Bella L.          1   \n",
       "1  Excellent view on the ocean at sunset.\\nExcell...   Rachou A.          1   \n",
       "2  This place was not what the reviews portrayed ...  Ozzetta B.          0   \n",
       "3  We were excited to repeat our Keoki's (in Kaua...   Arleen C.          0   \n",
       "4  If you're looking for a tourist spot, this is ...    Carol B.          0   \n",
       "\n",
       "   word_count  sent_count  chr_count  avg_word_len       ...        \\\n",
       "0         135          11        664      4.022222       ...         \n",
       "1          36           5        160      3.611111       ...         \n",
       "2         275          14       1229      3.596364       ...         \n",
       "3         475          34       2226      3.783158       ...         \n",
       "4         168          10        776      3.732143       ...         \n",
       "\n",
       "   ratio_content                                        sent_tokens  \\\n",
       "0       0.674074  [I stumbled across this great restaurant overl...   \n",
       "1       0.638889  [Excellent view on the ocean at sunset., Excel...   \n",
       "2       0.567273  [This place was not what the reviews portrayed...   \n",
       "3       0.604211  [We were excited to repeat our Keoki's (in Kau...   \n",
       "4       0.636905  [If you're looking for a tourist spot, this is...   \n",
       "\n",
       "                                     word_tokens_doc  \\\n",
       "0  [(I, stumbled, across, this, great, restaurant...   \n",
       "1  [(Excellent, view, on, the, ocean, at, sunset,...   \n",
       "2  [(This, place, was, not, what, the, reviews, p...   \n",
       "3  [(We, were, excited, to, repeat, our, Keoki, '...   \n",
       "4  [(If, you, 're, looking, for, a, tourist, spot...   \n",
       "\n",
       "                                     norm_tokens_doc  \\\n",
       "0  [(stumbl, across, great, restaur, overlook, oc...   \n",
       "1  [(excel, view, ocean, sunset), (excel, food), ...   \n",
       "2  [(place, review, portray), (starter, walk, sta...   \n",
       "3  [(excit, repeat, keoki, 's, kauai, lovefest, s...   \n",
       "4  [('re, look, tourist, spot), (unfortun, could,...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  [I, stumbled, across, this, great, restaurant,...   \n",
       "1  [Excellent, view, on, the, ocean, at, sunset, ...   \n",
       "2  [This, place, was, not, what, the, reviews, po...   \n",
       "3  [We, were, excited, to, repeat, our, Keoki, 's...   \n",
       "4  [If, you, 're, looking, for, a, tourist, spot,...   \n",
       "\n",
       "                                         norm_tokens  \\\n",
       "0  [stumbl, across, great, restaur, overlook, oce...   \n",
       "1  [excel, view, ocean, sunset, excel, food, fres...   \n",
       "2  [place, review, portray, starter, walk, stair,...   \n",
       "3  [excit, repeat, keoki, 's, kauai, lovefest, si...   \n",
       "4  ['re, look, tourist, spot, unfortun, could, n'...   \n",
       "\n",
       "                                         sent_topics  topic_mode  \\\n",
       "0  [(5, 0.3112545907497406), (5, 0.20203207433223...           5   \n",
       "1  [(5, 0.24188750982284546), (5, 0.1962578445672...           5   \n",
       "2  [(5, 0.19056889414787292), (5, 0.2658553421497...           5   \n",
       "3  [(5, 0.18351130187511444), (5, 0.2023473381996...           5   \n",
       "4  [(5, 0.21350185573101044), (5, 0.1800063550472...           5   \n",
       "\n",
       "                                          topic_list  svm_classifier  \n",
       "0                              5,5,9,5,3,4,5,5,5,9,5               1  \n",
       "1                                          5,5,3,5,5               1  \n",
       "2                        5,5,1,1,1,7,5,5,5,0,5,5,2,5               0  \n",
       "3  5,5,2,6,5,0,5,5,8,5,5,5,7,7,5,5,5,5,5,5,5,7,9,...               1  \n",
       "4                                5,5,2,6,9,5,9,0,5,5               1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../data/processed/yp_competitors_rws_0001_0050_complete.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
