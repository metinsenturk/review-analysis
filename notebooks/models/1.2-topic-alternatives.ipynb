{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alias</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>dataPublished</th>\n",
       "      <th>description</th>\n",
       "      <th>author</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>chr_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_content</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_tokens_doc</th>\n",
       "      <th>norm_tokens_doc</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>norm_tokens</th>\n",
       "      <th>sent_topics</th>\n",
       "      <th>topic_mode</th>\n",
       "      <th>topic_list</th>\n",
       "      <th>svm_classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>I stumbled across this great restaurant overlo...</td>\n",
       "      <td>Bella L.</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>11</td>\n",
       "      <td>664</td>\n",
       "      <td>4.022222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674074</td>\n",
       "      <td>['I stumbled across this great restaurant over...</td>\n",
       "      <td>[('I', 'stumbled', 'across', 'this', 'great', ...</td>\n",
       "      <td>[('stumbl', 'across', 'great', 'restaur', 'ove...</td>\n",
       "      <td>['I', 'stumbled', 'across', 'this', 'great', '...</td>\n",
       "      <td>['stumbl', 'across', 'great', 'restaur', 'over...</td>\n",
       "      <td>[(5, 0.181669682264328), (2, 0.186504259705543...</td>\n",
       "      <td>1</td>\n",
       "      <td>5,2,1,3,6,3,2,0,6,1,5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>Excellent view on the ocean at sunset.\\nExcell...</td>\n",
       "      <td>Rachou A.</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>160</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>['Excellent view on the ocean at sunset.', 'Ex...</td>\n",
       "      <td>[('Excellent', 'view', 'on', 'the', 'ocean', '...</td>\n",
       "      <td>[('excel', 'view', 'ocean', 'sunset'), ('excel...</td>\n",
       "      <td>['Excellent', 'view', 'on', 'the', 'ocean', 'a...</td>\n",
       "      <td>['excel', 'view', 'ocean', 'sunset', 'excel', ...</td>\n",
       "      <td>[(6, 0.146974578499794), (3, 0.139927998185157...</td>\n",
       "      <td>6</td>\n",
       "      <td>6,3,8,6,9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-12-25</td>\n",
       "      <td>This place was not what the reviews portrayed ...</td>\n",
       "      <td>Ozzetta B.</td>\n",
       "      <td>0</td>\n",
       "      <td>275</td>\n",
       "      <td>14</td>\n",
       "      <td>1229</td>\n",
       "      <td>3.596364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567273</td>\n",
       "      <td>['This place was not what the reviews portraye...</td>\n",
       "      <td>[('This', 'place', 'was', 'not', 'what', 'the'...</td>\n",
       "      <td>[('place', 'review', 'portray'), ('starter', '...</td>\n",
       "      <td>['This', 'place', 'was', 'not', 'what', 'the',...</td>\n",
       "      <td>['place', 'review', 'portray', 'starter', 'wal...</td>\n",
       "      <td>[(6, 0.15684203803539276), (8, 0.2266744673252...</td>\n",
       "      <td>8</td>\n",
       "      <td>6,8,2,5,4,8,3,9,8,8,8,1,7,6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-08</td>\n",
       "      <td>We were excited to repeat our Keoki's (in Kaua...</td>\n",
       "      <td>Arleen C.</td>\n",
       "      <td>0</td>\n",
       "      <td>475</td>\n",
       "      <td>34</td>\n",
       "      <td>2226</td>\n",
       "      <td>3.783158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604211</td>\n",
       "      <td>[\"We were excited to repeat our Keoki's (in Ka...</td>\n",
       "      <td>[('We', 'were', 'excited', 'to', 'repeat', 'ou...</td>\n",
       "      <td>[('excit', 'repeat', 'keoki', \"'s\", 'kauai', '...</td>\n",
       "      <td>['We', 'were', 'excited', 'to', 'repeat', 'our...</td>\n",
       "      <td>['excit', 'repeat', 'keoki', \"'s\", 'kauai', 'l...</td>\n",
       "      <td>[(2, 0.1735130101442337), (4, 0.13328838348388...</td>\n",
       "      <td>2</td>\n",
       "      <td>2,4,9,0,5,3,7,1,0,4,0,5,5,8,6,9,2,8,6,2,2,1,6,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>If you're looking for a tourist spot, this is ...</td>\n",
       "      <td>Carol B.</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>10</td>\n",
       "      <td>776</td>\n",
       "      <td>3.732143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636905</td>\n",
       "      <td>[\"If you're looking for a tourist spot, this i...</td>\n",
       "      <td>[('If', 'you', \"'re\", 'looking', 'for', 'a', '...</td>\n",
       "      <td>[(\"'re\", 'look', 'tourist', 'spot'), ('unfortu...</td>\n",
       "      <td>['If', 'you', \"'re\", 'looking', 'for', 'a', 't...</td>\n",
       "      <td>[\"'re\", 'look', 'tourist', 'spot', 'unfortun',...</td>\n",
       "      <td>[(6, 0.1469745934009552), (9, 0.20430350303649...</td>\n",
       "      <td>6</td>\n",
       "      <td>6,9,8,6,4,0,5,3,1,9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                alias  ratingValue dataPublished  \\\n",
       "0  kimos-maui-lahaina            5    2019-01-06   \n",
       "1  kimos-maui-lahaina            5    2019-01-04   \n",
       "2  kimos-maui-lahaina            3    2018-12-25   \n",
       "3  kimos-maui-lahaina            2    2018-12-08   \n",
       "4  kimos-maui-lahaina            3    2018-11-29   \n",
       "\n",
       "                                         description      author  sentiment  \\\n",
       "0  I stumbled across this great restaurant overlo...    Bella L.          1   \n",
       "1  Excellent view on the ocean at sunset.\\nExcell...   Rachou A.          1   \n",
       "2  This place was not what the reviews portrayed ...  Ozzetta B.          0   \n",
       "3  We were excited to repeat our Keoki's (in Kaua...   Arleen C.          0   \n",
       "4  If you're looking for a tourist spot, this is ...    Carol B.          0   \n",
       "\n",
       "   word_count  sent_count  chr_count  avg_word_len       ...        \\\n",
       "0         135          11        664      4.022222       ...         \n",
       "1          36           5        160      3.611111       ...         \n",
       "2         275          14       1229      3.596364       ...         \n",
       "3         475          34       2226      3.783158       ...         \n",
       "4         168          10        776      3.732143       ...         \n",
       "\n",
       "   ratio_content                                        sent_tokens  \\\n",
       "0       0.674074  ['I stumbled across this great restaurant over...   \n",
       "1       0.638889  ['Excellent view on the ocean at sunset.', 'Ex...   \n",
       "2       0.567273  ['This place was not what the reviews portraye...   \n",
       "3       0.604211  [\"We were excited to repeat our Keoki's (in Ka...   \n",
       "4       0.636905  [\"If you're looking for a tourist spot, this i...   \n",
       "\n",
       "                                     word_tokens_doc  \\\n",
       "0  [('I', 'stumbled', 'across', 'this', 'great', ...   \n",
       "1  [('Excellent', 'view', 'on', 'the', 'ocean', '...   \n",
       "2  [('This', 'place', 'was', 'not', 'what', 'the'...   \n",
       "3  [('We', 'were', 'excited', 'to', 'repeat', 'ou...   \n",
       "4  [('If', 'you', \"'re\", 'looking', 'for', 'a', '...   \n",
       "\n",
       "                                     norm_tokens_doc  \\\n",
       "0  [('stumbl', 'across', 'great', 'restaur', 'ove...   \n",
       "1  [('excel', 'view', 'ocean', 'sunset'), ('excel...   \n",
       "2  [('place', 'review', 'portray'), ('starter', '...   \n",
       "3  [('excit', 'repeat', 'keoki', \"'s\", 'kauai', '...   \n",
       "4  [(\"'re\", 'look', 'tourist', 'spot'), ('unfortu...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  ['I', 'stumbled', 'across', 'this', 'great', '...   \n",
       "1  ['Excellent', 'view', 'on', 'the', 'ocean', 'a...   \n",
       "2  ['This', 'place', 'was', 'not', 'what', 'the',...   \n",
       "3  ['We', 'were', 'excited', 'to', 'repeat', 'our...   \n",
       "4  ['If', 'you', \"'re\", 'looking', 'for', 'a', 't...   \n",
       "\n",
       "                                         norm_tokens  \\\n",
       "0  ['stumbl', 'across', 'great', 'restaur', 'over...   \n",
       "1  ['excel', 'view', 'ocean', 'sunset', 'excel', ...   \n",
       "2  ['place', 'review', 'portray', 'starter', 'wal...   \n",
       "3  ['excit', 'repeat', 'keoki', \"'s\", 'kauai', 'l...   \n",
       "4  [\"'re\", 'look', 'tourist', 'spot', 'unfortun',...   \n",
       "\n",
       "                                         sent_topics  topic_mode  \\\n",
       "0  [(5, 0.181669682264328), (2, 0.186504259705543...           1   \n",
       "1  [(6, 0.146974578499794), (3, 0.139927998185157...           6   \n",
       "2  [(6, 0.15684203803539276), (8, 0.2266744673252...           8   \n",
       "3  [(2, 0.1735130101442337), (4, 0.13328838348388...           2   \n",
       "4  [(6, 0.1469745934009552), (9, 0.20430350303649...           6   \n",
       "\n",
       "                                          topic_list  svm_classifier  \n",
       "0                              5,2,1,3,6,3,2,0,6,1,5               1  \n",
       "1                                          6,3,8,6,9               1  \n",
       "2                        6,8,2,5,4,8,3,9,8,8,8,1,7,6               0  \n",
       "3  2,4,9,0,5,3,7,1,0,4,0,5,5,8,6,9,2,8,6,2,2,1,6,...               1  \n",
       "4                                6,9,8,6,4,0,5,3,1,9               1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"../../data/processed/yp_competitors_rws_0001_0050_complete.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_tokens_doc</th>\n",
       "      <th>norm_tokens_doc</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>norm_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[I stumbled across this great restaurant overl...</td>\n",
       "      <td>[(I, stumbled, across, this, great, restaurant...</td>\n",
       "      <td>[(stumbl, across, great, restaur, overlook, oc...</td>\n",
       "      <td>[I, stumbled, across, this, great, restaurant,...</td>\n",
       "      <td>[stumbl, across, great, restaur, overlook, oce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Excellent view on the ocean at sunset., Excel...</td>\n",
       "      <td>[(Excellent, view, on, the, ocean, at, sunset,...</td>\n",
       "      <td>[(excel, view, ocean, sunset), (excel, food), ...</td>\n",
       "      <td>[Excellent, view, on, the, ocean, at, sunset, ...</td>\n",
       "      <td>[excel, view, ocean, sunset, excel, food, fres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[This place was not what the reviews portrayed...</td>\n",
       "      <td>[(This, place, was, not, what, the, reviews, p...</td>\n",
       "      <td>[(place, review, portray), (starter, walk, sta...</td>\n",
       "      <td>[This, place, was, not, what, the, reviews, po...</td>\n",
       "      <td>[place, review, portray, starter, walk, stair,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[We were excited to repeat our Keoki's (in Kau...</td>\n",
       "      <td>[(We, were, excited, to, repeat, our, Keoki, '...</td>\n",
       "      <td>[(excit, repeat, keoki, 's, kauai, lovefest, s...</td>\n",
       "      <td>[We, were, excited, to, repeat, our, Keoki, 's...</td>\n",
       "      <td>[excit, repeat, keoki, 's, kauai, lovefest, si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[If you're looking for a tourist spot, this is...</td>\n",
       "      <td>[(If, you, 're, looking, for, a, tourist, spot...</td>\n",
       "      <td>[('re, look, tourist, spot), (unfortun, could,...</td>\n",
       "      <td>[If, you, 're, looking, for, a, tourist, spot,...</td>\n",
       "      <td>['re, look, tourist, spot, unfortun, could, n'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[What an amazing restaurant, especially the vi...</td>\n",
       "      <td>[(What, an, amazing, restaurant, ,, especially...</td>\n",
       "      <td>[(amaz, restaur, especi, view, dinner), (dine,...</td>\n",
       "      <td>[What, an, amazing, restaurant, ,, especially,...</td>\n",
       "      <td>[amaz, restaur, especi, view, dinner, dine, wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sent_tokens  \\\n",
       "0  [I stumbled across this great restaurant overl...   \n",
       "1  [Excellent view on the ocean at sunset., Excel...   \n",
       "2  [This place was not what the reviews portrayed...   \n",
       "3  [We were excited to repeat our Keoki's (in Kau...   \n",
       "4  [If you're looking for a tourist spot, this is...   \n",
       "5  [What an amazing restaurant, especially the vi...   \n",
       "\n",
       "                                     word_tokens_doc  \\\n",
       "0  [(I, stumbled, across, this, great, restaurant...   \n",
       "1  [(Excellent, view, on, the, ocean, at, sunset,...   \n",
       "2  [(This, place, was, not, what, the, reviews, p...   \n",
       "3  [(We, were, excited, to, repeat, our, Keoki, '...   \n",
       "4  [(If, you, 're, looking, for, a, tourist, spot...   \n",
       "5  [(What, an, amazing, restaurant, ,, especially...   \n",
       "\n",
       "                                     norm_tokens_doc  \\\n",
       "0  [(stumbl, across, great, restaur, overlook, oc...   \n",
       "1  [(excel, view, ocean, sunset), (excel, food), ...   \n",
       "2  [(place, review, portray), (starter, walk, sta...   \n",
       "3  [(excit, repeat, keoki, 's, kauai, lovefest, s...   \n",
       "4  [('re, look, tourist, spot), (unfortun, could,...   \n",
       "5  [(amaz, restaur, especi, view, dinner), (dine,...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  [I, stumbled, across, this, great, restaurant,...   \n",
       "1  [Excellent, view, on, the, ocean, at, sunset, ...   \n",
       "2  [This, place, was, not, what, the, reviews, po...   \n",
       "3  [We, were, excited, to, repeat, our, Keoki, 's...   \n",
       "4  [If, you, 're, looking, for, a, tourist, spot,...   \n",
       "5  [What, an, amazing, restaurant, ,, especially,...   \n",
       "\n",
       "                                         norm_tokens  \n",
       "0  [stumbl, across, great, restaur, overlook, oce...  \n",
       "1  [excel, view, ocean, sunset, excel, food, fres...  \n",
       "2  [place, review, portray, starter, walk, stair,...  \n",
       "3  [excit, repeat, keoki, 's, kauai, lovefest, si...  \n",
       "4  ['re, look, tourist, spot, unfortun, could, n'...  \n",
       "5  [amaz, restaur, especi, view, dinner, dine, wa...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix column type error\n",
    "from ast import literal_eval\n",
    "\n",
    "fix_columns_list = ['sent_tokens', 'word_tokens_doc', 'norm_tokens_doc', 'word_tokens', 'norm_tokens']\n",
    "for column in fix_columns_list:\n",
    "    df[column] = df[column].apply(lambda x: literal_eval(x))\n",
    "df.loc[:5, fix_columns_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<itertools.chain at 0x10d63bfd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "chain(*df.norm_tokens[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "data = pd.Series(list(chain(*df.norm_tokens_doc[:100])), name='norm_tokens_doc')\n",
    "data = list(chain(*df.norm_tokens_doc[:100]))\n",
    "\n",
    "id2word = Dictionary(documents=data)\n",
    "doc_term_matrix = [id2word.doc2bow(doc) for doc in data]\n",
    "doc_term_matrix[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('stumbl',\n",
       " 'across',\n",
       " 'great',\n",
       " 'restaur',\n",
       " 'overlook',\n",
       " 'ocean',\n",
       " 'lunch',\n",
       " 'vacat',\n",
       " 'maui')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.007*salsa + 0.006*a- + 0.006*argument + 0.005*seafood'),\n",
       " (1, '0.005*ono + 0.005*sprout + 0.004*cake + 0.004*truli'),\n",
       " (2, '0.005*well + 0.005*unless + 0.004*breakfast + 0.004*chop')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import HdpModel\n",
    "\n",
    "hdp_model = HdpModel(doc_term_matrix, id2word)\n",
    "hdp_model.show_topics(num_words=4, num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.522*\"\\'s\" + 0.326*\"kimo\" + 0.215*\"fish\" + 0.210*\"view\"'),\n",
       " (1, '-0.549*\"\\'s\" + -0.347*\"kimo\" + 0.345*\"view\" + 0.220*\"fish\"'),\n",
       " (2, '0.590*\"fish\" + -0.365*\"view\" + 0.284*\"mahi\" + 0.266*\"order\"')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import LsiModel\n",
    "lsi_model = LsiModel(corpus=doc_term_matrix, num_topics=10, id2word=id2word)\n",
    "lsi_model.show_topics(num_words=4, num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.4577767745022286),\n",
       " (1, -0.3394702397301862),\n",
       " (2, 0.43806532995484854),\n",
       " (3, -0.24163345759488503),\n",
       " (4, 0.12888575129368146),\n",
       " (5, -0.11204414833687067),\n",
       " (6, -0.0816756155945271),\n",
       " (7, -0.48514348673887825),\n",
       " (8, -0.29732854727856384),\n",
       " (9, 0.7437154251852944)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_list = lsi_model[doc_term_matrix[0]]\n",
    "max(doc_topic_list, key=lambda x: x[1])\n",
    "doc_topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/text/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py:442: RuntimeWarning: invalid value encountered in true_divide\n",
      "  topic = topic / topic.sum()  # normalize to probability dist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(7, 'nan*\"1003\" + nan*\"1005\" + nan*\"1001\" + nan*\"1002\"'),\n",
       " (8, 'nan*\"1003\" + nan*\"1005\" + nan*\"1001\" + nan*\"1002\"'),\n",
       " (0, 'nan*\"1003\" + nan*\"1005\" + nan*\"1001\" + nan*\"1002\"')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.wrappers import LdaMallet\n",
    "\n",
    "mallet_path = '../../model/mallet-2.0.8/bin/mallet'\n",
    "lda_mallet = LdaMallet(mallet_path, doc_term_matrix, num_topics=10)\n",
    "lda_mallet.show_topics(num_words=4, num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LdaMallet == type(lda_mallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 0.125)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_list = lda_mallet[doc_term_matrix][1]\n",
    "doc_topic_list\n",
    "max(doc_topic_list, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.035*\"\\'s\" + 0.016*\"kimo\" + 0.010*\"fish\" + 0.008*\"go\"'),\n",
       " (5, '0.017*\"\\'s\" + 0.014*\"fish\" + 0.014*\"good\" + 0.011*\"got\"'),\n",
       " (3, '0.022*\"\\'s\" + 0.016*\"pie\" + 0.015*\"fish\" + 0.015*\"hula\"')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import LdaModel\n",
    "lda_model = LdaModel(corpus=doc_term_matrix, id2word=id2word, num_topics=10)\n",
    "[i for i in lda_model[doc_term_matrix[0:1]]]\n",
    "lda_model.show_topics(num_words=4, num_topics=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '-0.626*\"lunch\" + -0.494*\"stumbl\" + 0.361*\"maui\" + 0.334*\"across\"'),\n",
       " (1, '0.638*\"ocean\" + 0.481*\"restaur\" + -0.380*\"maui\" + -0.236*\"across\"'),\n",
       " (2, '-0.634*\"vacat\" + 0.560*\"maui\" + -0.330*\"across\" + 0.316*\"stumbl\"')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import RpModel\n",
    "\n",
    "# transformation like\n",
    "rp_model = RpModel(doc_term_matrix, id2word, num_topics=10)\n",
    "lsi_model = LsiModel(corpus=rp_model[doc_term_matrix], num_topics=10, id2word=id2word)\n",
    "lsi_model.show_topics(num_words=4, num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, '0.010*\"view\" + 0.008*\"good\" + 0.008*\"excel\" + 0.008*\"realli\"'),\n",
       " (8, '0.012*\"hula\" + 0.011*\"pie\" + 0.008*\"great\" + 0.007*\"get\"'),\n",
       " (2, '0.007*\"definit\" + 0.007*\"back\" + 0.007*\"view\" + 0.006*\"visit\"')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import TfidfModel\n",
    "\n",
    "# transformation like\n",
    "tfidf_model = TfidfModel(id2word=id2word, corpus=doc_term_matrix)\n",
    "tfidf_model[doc_term_matrix[0]]\n",
    "lda_model = LdaModel(corpus=tfidf_model[doc_term_matrix], id2word=id2word, num_topics=10)\n",
    "lda_model.show_topics(num_words=4, num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, '0.014*\"drink\" + 0.013*\"\\'s\" + 0.009*\"fish\" + 0.008*\"better\"'),\n",
       " (6, '0.017*\"food\" + 0.011*\"\\'s\" + 0.008*\"realli\" + 0.008*\"servic\"'),\n",
       " (4, '0.023*\"view\" + 0.014*\"would\" + 0.012*\"fish\" + 0.011*\"good\"')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import NormModel\n",
    "\n",
    "norm_model = NormModel(doc_term_matrix, norm='l2')\n",
    "\n",
    "doc_term_matrix = [norm_model[id2word.doc2bow(doc)] for doc in data]\n",
    "lda_model = LdaModel(corpus=doc_term_matrix, id2word=id2word, num_topics=10)\n",
    "lda_model.show_topics(num_words=4, num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '-0.360*\"view\" + -0.350*\"food\" + -0.272*\"great\" + -0.222*\"good\"'),\n",
       " (1, '0.503*\"food\" + 0.444*\"delici\" + 0.359*\"good\" + -0.308*\"view\"'),\n",
       " (2, '0.522*\"view\" + -0.265*\"\\'s\" + -0.253*\"pie\" + -0.248*\"hula\"')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import LogEntropyModel\n",
    "log_model = LogEntropyModel(doc_term_matrix)\n",
    "lsi_model = LsiModel(corpus=log_model[doc_term_matrix], num_topics=10, id2word=id2word)\n",
    "lsi_model.show_topics(num_words=4, num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
