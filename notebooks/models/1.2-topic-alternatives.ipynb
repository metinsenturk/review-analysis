{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alias</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>dataPublished</th>\n",
       "      <th>description</th>\n",
       "      <th>author</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>chr_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_lexical</th>\n",
       "      <th>ratio_content</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_tokens_doc</th>\n",
       "      <th>norm_tokens_doc</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>norm_tokens</th>\n",
       "      <th>sent_topics</th>\n",
       "      <th>topic_mode</th>\n",
       "      <th>topic_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>I stumbled across this great restaurant overlo...</td>\n",
       "      <td>Bella L.</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>11</td>\n",
       "      <td>664</td>\n",
       "      <td>4.022222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637037</td>\n",
       "      <td>0.674074</td>\n",
       "      <td>['I stumbled across this great restaurant over...</td>\n",
       "      <td>[('I', 'stumbled', 'across', 'this', 'great', ...</td>\n",
       "      <td>[('stumbl', 'across', 'great', 'restaur', 'ove...</td>\n",
       "      <td>['I', 'stumbled', 'across', 'this', 'great', '...</td>\n",
       "      <td>['stumbl', 'across', 'great', 'restaur', 'over...</td>\n",
       "      <td>[(5, 0.181669682264328), (2, 0.186504259705543...</td>\n",
       "      <td>1</td>\n",
       "      <td>5,2,1,3,6,3,2,0,6,1,5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>Excellent view on the ocean at sunset.\\nExcell...</td>\n",
       "      <td>Rachou A.</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>160</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>['Excellent view on the ocean at sunset.', 'Ex...</td>\n",
       "      <td>[('Excellent', 'view', 'on', 'the', 'ocean', '...</td>\n",
       "      <td>[('excel', 'view', 'ocean', 'sunset'), ('excel...</td>\n",
       "      <td>['Excellent', 'view', 'on', 'the', 'ocean', 'a...</td>\n",
       "      <td>['excel', 'view', 'ocean', 'sunset', 'excel', ...</td>\n",
       "      <td>[(6, 0.146974578499794), (3, 0.139927998185157...</td>\n",
       "      <td>6</td>\n",
       "      <td>6,3,8,6,9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-12-25</td>\n",
       "      <td>This place was not what the reviews portrayed ...</td>\n",
       "      <td>Ozzetta B.</td>\n",
       "      <td>0</td>\n",
       "      <td>275</td>\n",
       "      <td>14</td>\n",
       "      <td>1229</td>\n",
       "      <td>3.596364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534545</td>\n",
       "      <td>0.567273</td>\n",
       "      <td>['This place was not what the reviews portraye...</td>\n",
       "      <td>[('This', 'place', 'was', 'not', 'what', 'the'...</td>\n",
       "      <td>[('place', 'review', 'portray'), ('starter', '...</td>\n",
       "      <td>['This', 'place', 'was', 'not', 'what', 'the',...</td>\n",
       "      <td>['place', 'review', 'portray', 'starter', 'wal...</td>\n",
       "      <td>[(6, 0.15684203803539276), (8, 0.2266744673252...</td>\n",
       "      <td>8</td>\n",
       "      <td>6,8,2,5,4,8,3,9,8,8,8,1,7,6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-08</td>\n",
       "      <td>We were excited to repeat our Keoki's (in Kaua...</td>\n",
       "      <td>Arleen C.</td>\n",
       "      <td>0</td>\n",
       "      <td>475</td>\n",
       "      <td>34</td>\n",
       "      <td>2226</td>\n",
       "      <td>3.783158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484211</td>\n",
       "      <td>0.604211</td>\n",
       "      <td>[\"We were excited to repeat our Keoki's (in Ka...</td>\n",
       "      <td>[('We', 'were', 'excited', 'to', 'repeat', 'ou...</td>\n",
       "      <td>[('excit', 'repeat', 'keoki', \"'s\", 'kauai', '...</td>\n",
       "      <td>['We', 'were', 'excited', 'to', 'repeat', 'our...</td>\n",
       "      <td>['excit', 'repeat', 'keoki', \"'s\", 'kauai', 'l...</td>\n",
       "      <td>[(2, 0.1735130101442337), (4, 0.13328838348388...</td>\n",
       "      <td>2</td>\n",
       "      <td>2,4,9,0,5,3,7,1,0,4,0,5,5,8,6,9,2,8,6,2,2,1,6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>If you're looking for a tourist spot, this is ...</td>\n",
       "      <td>Carol B.</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>10</td>\n",
       "      <td>776</td>\n",
       "      <td>3.732143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.648810</td>\n",
       "      <td>0.636905</td>\n",
       "      <td>[\"If you're looking for a tourist spot, this i...</td>\n",
       "      <td>[('If', 'you', \"'re\", 'looking', 'for', 'a', '...</td>\n",
       "      <td>[(\"'re\", 'look', 'tourist', 'spot'), ('unfortu...</td>\n",
       "      <td>['If', 'you', \"'re\", 'looking', 'for', 'a', 't...</td>\n",
       "      <td>[\"'re\", 'look', 'tourist', 'spot', 'unfortun',...</td>\n",
       "      <td>[(6, 0.1469745934009552), (9, 0.20430350303649...</td>\n",
       "      <td>6</td>\n",
       "      <td>6,9,8,6,4,0,5,3,1,9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                alias  ratingValue dataPublished  \\\n",
       "0  kimos-maui-lahaina            5    2019-01-06   \n",
       "1  kimos-maui-lahaina            5    2019-01-04   \n",
       "2  kimos-maui-lahaina            3    2018-12-25   \n",
       "3  kimos-maui-lahaina            2    2018-12-08   \n",
       "4  kimos-maui-lahaina            3    2018-11-29   \n",
       "\n",
       "                                         description      author  sentiment  \\\n",
       "0  I stumbled across this great restaurant overlo...    Bella L.          1   \n",
       "1  Excellent view on the ocean at sunset.\\nExcell...   Rachou A.          1   \n",
       "2  This place was not what the reviews portrayed ...  Ozzetta B.          0   \n",
       "3  We were excited to repeat our Keoki's (in Kaua...   Arleen C.          0   \n",
       "4  If you're looking for a tourist spot, this is ...    Carol B.          0   \n",
       "\n",
       "   word_count  sent_count  chr_count  avg_word_len  \\\n",
       "0         135          11        664      4.022222   \n",
       "1          36           5        160      3.611111   \n",
       "2         275          14       1229      3.596364   \n",
       "3         475          34       2226      3.783158   \n",
       "4         168          10        776      3.732143   \n",
       "\n",
       "                         ...                          ratio_lexical  \\\n",
       "0                        ...                               0.637037   \n",
       "1                        ...                               0.777778   \n",
       "2                        ...                               0.534545   \n",
       "3                        ...                               0.484211   \n",
       "4                        ...                               0.648810   \n",
       "\n",
       "   ratio_content                                        sent_tokens  \\\n",
       "0       0.674074  ['I stumbled across this great restaurant over...   \n",
       "1       0.638889  ['Excellent view on the ocean at sunset.', 'Ex...   \n",
       "2       0.567273  ['This place was not what the reviews portraye...   \n",
       "3       0.604211  [\"We were excited to repeat our Keoki's (in Ka...   \n",
       "4       0.636905  [\"If you're looking for a tourist spot, this i...   \n",
       "\n",
       "                                     word_tokens_doc  \\\n",
       "0  [('I', 'stumbled', 'across', 'this', 'great', ...   \n",
       "1  [('Excellent', 'view', 'on', 'the', 'ocean', '...   \n",
       "2  [('This', 'place', 'was', 'not', 'what', 'the'...   \n",
       "3  [('We', 'were', 'excited', 'to', 'repeat', 'ou...   \n",
       "4  [('If', 'you', \"'re\", 'looking', 'for', 'a', '...   \n",
       "\n",
       "                                     norm_tokens_doc  \\\n",
       "0  [('stumbl', 'across', 'great', 'restaur', 'ove...   \n",
       "1  [('excel', 'view', 'ocean', 'sunset'), ('excel...   \n",
       "2  [('place', 'review', 'portray'), ('starter', '...   \n",
       "3  [('excit', 'repeat', 'keoki', \"'s\", 'kauai', '...   \n",
       "4  [(\"'re\", 'look', 'tourist', 'spot'), ('unfortu...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  ['I', 'stumbled', 'across', 'this', 'great', '...   \n",
       "1  ['Excellent', 'view', 'on', 'the', 'ocean', 'a...   \n",
       "2  ['This', 'place', 'was', 'not', 'what', 'the',...   \n",
       "3  ['We', 'were', 'excited', 'to', 'repeat', 'our...   \n",
       "4  ['If', 'you', \"'re\", 'looking', 'for', 'a', 't...   \n",
       "\n",
       "                                         norm_tokens  \\\n",
       "0  ['stumbl', 'across', 'great', 'restaur', 'over...   \n",
       "1  ['excel', 'view', 'ocean', 'sunset', 'excel', ...   \n",
       "2  ['place', 'review', 'portray', 'starter', 'wal...   \n",
       "3  ['excit', 'repeat', 'keoki', \"'s\", 'kauai', 'l...   \n",
       "4  [\"'re\", 'look', 'tourist', 'spot', 'unfortun',...   \n",
       "\n",
       "                                         sent_topics  topic_mode  \\\n",
       "0  [(5, 0.181669682264328), (2, 0.186504259705543...           1   \n",
       "1  [(6, 0.146974578499794), (3, 0.139927998185157...           6   \n",
       "2  [(6, 0.15684203803539276), (8, 0.2266744673252...           8   \n",
       "3  [(2, 0.1735130101442337), (4, 0.13328838348388...           2   \n",
       "4  [(6, 0.1469745934009552), (9, 0.20430350303649...           6   \n",
       "\n",
       "                                          topic_list  \n",
       "0                              5,2,1,3,6,3,2,0,6,1,5  \n",
       "1                                          6,3,8,6,9  \n",
       "2                        6,8,2,5,4,8,3,9,8,8,8,1,7,6  \n",
       "3  2,4,9,0,5,3,7,1,0,4,0,5,5,8,6,9,2,8,6,2,2,1,6,...  \n",
       "4                                6,9,8,6,4,0,5,3,1,9  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"../../data/processed/yp_competitors_rws_0001_0050_topics.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_tokens_doc</th>\n",
       "      <th>norm_tokens_doc</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>norm_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[I stumbled across this great restaurant overl...</td>\n",
       "      <td>[(I, stumbled, across, this, great, restaurant...</td>\n",
       "      <td>[(stumbl, across, great, restaur, overlook, oc...</td>\n",
       "      <td>[I, stumbled, across, this, great, restaurant,...</td>\n",
       "      <td>[stumbl, across, great, restaur, overlook, oce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Excellent view on the ocean at sunset., Excel...</td>\n",
       "      <td>[(Excellent, view, on, the, ocean, at, sunset,...</td>\n",
       "      <td>[(excel, view, ocean, sunset), (excel, food), ...</td>\n",
       "      <td>[Excellent, view, on, the, ocean, at, sunset, ...</td>\n",
       "      <td>[excel, view, ocean, sunset, excel, food, fres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[This place was not what the reviews portrayed...</td>\n",
       "      <td>[(This, place, was, not, what, the, reviews, p...</td>\n",
       "      <td>[(place, review, portray), (starter, walk, sta...</td>\n",
       "      <td>[This, place, was, not, what, the, reviews, po...</td>\n",
       "      <td>[place, review, portray, starter, walk, stair,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[We were excited to repeat our Keoki's (in Kau...</td>\n",
       "      <td>[(We, were, excited, to, repeat, our, Keoki, '...</td>\n",
       "      <td>[(excit, repeat, keoki, 's, kauai, lovefest, s...</td>\n",
       "      <td>[We, were, excited, to, repeat, our, Keoki, 's...</td>\n",
       "      <td>[excit, repeat, keoki, 's, kauai, lovefest, si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[If you're looking for a tourist spot, this is...</td>\n",
       "      <td>[(If, you, 're, looking, for, a, tourist, spot...</td>\n",
       "      <td>[('re, look, tourist, spot), (unfortun, could,...</td>\n",
       "      <td>[If, you, 're, looking, for, a, tourist, spot,...</td>\n",
       "      <td>['re, look, tourist, spot, unfortun, could, n'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[What an amazing restaurant, especially the vi...</td>\n",
       "      <td>[(What, an, amazing, restaurant, ,, especially...</td>\n",
       "      <td>[(amaz, restaur, especi, view, dinner), (dine,...</td>\n",
       "      <td>[What, an, amazing, restaurant, ,, especially,...</td>\n",
       "      <td>[amaz, restaur, especi, view, dinner, dine, wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sent_tokens  \\\n",
       "0  [I stumbled across this great restaurant overl...   \n",
       "1  [Excellent view on the ocean at sunset., Excel...   \n",
       "2  [This place was not what the reviews portrayed...   \n",
       "3  [We were excited to repeat our Keoki's (in Kau...   \n",
       "4  [If you're looking for a tourist spot, this is...   \n",
       "5  [What an amazing restaurant, especially the vi...   \n",
       "\n",
       "                                     word_tokens_doc  \\\n",
       "0  [(I, stumbled, across, this, great, restaurant...   \n",
       "1  [(Excellent, view, on, the, ocean, at, sunset,...   \n",
       "2  [(This, place, was, not, what, the, reviews, p...   \n",
       "3  [(We, were, excited, to, repeat, our, Keoki, '...   \n",
       "4  [(If, you, 're, looking, for, a, tourist, spot...   \n",
       "5  [(What, an, amazing, restaurant, ,, especially...   \n",
       "\n",
       "                                     norm_tokens_doc  \\\n",
       "0  [(stumbl, across, great, restaur, overlook, oc...   \n",
       "1  [(excel, view, ocean, sunset), (excel, food), ...   \n",
       "2  [(place, review, portray), (starter, walk, sta...   \n",
       "3  [(excit, repeat, keoki, 's, kauai, lovefest, s...   \n",
       "4  [('re, look, tourist, spot), (unfortun, could,...   \n",
       "5  [(amaz, restaur, especi, view, dinner), (dine,...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  [I, stumbled, across, this, great, restaurant,...   \n",
       "1  [Excellent, view, on, the, ocean, at, sunset, ...   \n",
       "2  [This, place, was, not, what, the, reviews, po...   \n",
       "3  [We, were, excited, to, repeat, our, Keoki, 's...   \n",
       "4  [If, you, 're, looking, for, a, tourist, spot,...   \n",
       "5  [What, an, amazing, restaurant, ,, especially,...   \n",
       "\n",
       "                                         norm_tokens  \n",
       "0  [stumbl, across, great, restaur, overlook, oce...  \n",
       "1  [excel, view, ocean, sunset, excel, food, fres...  \n",
       "2  [place, review, portray, starter, walk, stair,...  \n",
       "3  [excit, repeat, keoki, 's, kauai, lovefest, si...  \n",
       "4  ['re, look, tourist, spot, unfortun, could, n'...  \n",
       "5  [amaz, restaur, especi, view, dinner, dine, wa...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix column type error\n",
    "from ast import literal_eval\n",
    "\n",
    "fix_columns_list = ['sent_tokens', 'word_tokens_doc', 'norm_tokens_doc', 'word_tokens', 'norm_tokens']\n",
    "for column in fix_columns_list:\n",
    "    df[column] = df[column].apply(lambda x: literal_eval(x))\n",
    "df.loc[:5, fix_columns_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<itertools.chain at 0x12be18278>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "chain(*df.norm_tokens[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Doc Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "data = pd.Series(list(chain(*df.norm_tokens_doc[:100])), name='norm_tokens_doc')\n",
    "data = list(chain(*df.norm_tokens_doc[:100]))\n",
    "\n",
    "id2word = Dictionary(documents=data)\n",
    "doc_term_matrix = [id2word.doc2bow(doc) for doc in data]\n",
    "doc_term_matrix[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stumbl',\n",
       "  'across',\n",
       "  'great',\n",
       "  'restaur',\n",
       "  'overlook',\n",
       "  'ocean',\n",
       "  'lunch',\n",
       "  'vacat',\n",
       "  'maui'),\n",
       " ('high', 'expect', 'place', 'boy', 'blow', 'water'),\n",
       " ('fish', 'chip', 'best', \"'ve\", 'ever', \"'ve\", 'lot', 'includ', 'london'),\n",
       " ('highli', 'recommend'),\n",
       " ('also', 'turkey', 'bacon', 'sandwich', 'good')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.007*salsa + 0.006*a- + 0.006*argument + 0.005*seafood'),\n",
       " (1, '0.005*ono + 0.005*sprout + 0.004*cake + 0.004*truli'),\n",
       " (2, '0.005*well + 0.005*unless + 0.004*breakfast + 0.004*chop')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import HdpModel\n",
    "\n",
    "hdp_model = HdpModel(doc_term_matrix, id2word)\n",
    "hdp_model.show_topics(num_words=4, num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.522*\"\\'s\" + 0.326*\"kimo\" + 0.215*\"fish\" + 0.210*\"view\"'),\n",
       " (1, '0.549*\"\\'s\" + 0.347*\"kimo\" + -0.345*\"view\" + -0.220*\"fish\"'),\n",
       " (2, '-0.590*\"fish\" + 0.365*\"view\" + -0.284*\"mahi\" + -0.266*\"order\"')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import LsiModel\n",
    "lsi_model = LsiModel(corpus=doc_term_matrix, num_topics=10, id2word=id2word)\n",
    "lsi_model.show_topics(num_words=4, num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.4577767745022286),\n",
       " (1, -0.3394702397301862),\n",
       " (2, 0.43806532995484854),\n",
       " (3, -0.24163345759488503),\n",
       " (4, 0.12888575129368146),\n",
       " (5, -0.11204414833687067),\n",
       " (6, -0.0816756155945271),\n",
       " (7, -0.48514348673887825),\n",
       " (8, -0.29732854727856384),\n",
       " (9, 0.7437154251852944)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_list = lsi_model[doc_term_matrix[0]]\n",
    "max(doc_topic_list, key=lambda x: x[1])\n",
    "doc_topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/text/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py:442: RuntimeWarning: invalid value encountered in true_divide\n",
      "  topic = topic / topic.sum()  # normalize to probability dist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(7, 'nan*\"1003\" + nan*\"1005\" + nan*\"1001\" + nan*\"1002\"'),\n",
       " (8, 'nan*\"1003\" + nan*\"1005\" + nan*\"1001\" + nan*\"1002\"'),\n",
       " (0, 'nan*\"1003\" + nan*\"1005\" + nan*\"1001\" + nan*\"1002\"')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.wrappers import LdaMallet\n",
    "\n",
    "mallet_path = '../../model/mallet-2.0.8/bin/mallet'\n",
    "lda_mallet = LdaMallet(mallet_path, doc_term_matrix, num_topics=10)\n",
    "lda_mallet.show_topics(num_words=4, num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LdaMallet == type(lda_mallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 0.125)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_list = lda_mallet[doc_term_matrix][1]\n",
    "doc_topic_list\n",
    "max(doc_topic_list, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_document_topics() missing 2 required positional arguments: 'self' and 'bow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-08dc5083919a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLdaModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mLdaModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_document_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: get_document_topics() missing 2 required positional arguments: 'self' and 'bow'"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaModel\n",
    "LdaModel.get_document_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1.5811388492584229),\n",
       " (1, -0.3162277042865753),\n",
       " (2, -0.9486832618713379),\n",
       " (3, -0.3162277638912201),\n",
       " (4, -0.3162277638912201),\n",
       " (5, 0.3162277638912201),\n",
       " (6, 0.3162277638912201),\n",
       " (7, 0.9486832618713379),\n",
       " (8, -0.9486832618713379),\n",
       " (9, 0.3162277638912201)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import RpModel\n",
    "\n",
    "# transformation like\n",
    "rp_model = RpModel(doc_term_matrix, id2word, num_topics=10)\n",
    "rp_model[doc_term_matrix[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.3890684642963089),\n",
       " (1, 0.21013991003912663),\n",
       " (2, 0.2865653223505219),\n",
       " (3, 0.24175593745239612),\n",
       " (4, 0.2374611467358843),\n",
       " (5, 0.4094485385475573),\n",
       " (6, 0.22594792374576136),\n",
       " (7, 0.4872768155255841),\n",
       " (8, 0.3890684642963089)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import TfidfModel\n",
    "\n",
    "# transformation like\n",
    "tfidf_model = TfidfModel(id2word=id2word, corpus=doc_term_matrix)\n",
    "tfidf_model[doc_term_matrix[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.3333333333333333),\n",
       " (1, 0.3333333333333333),\n",
       " (2, 0.3333333333333333),\n",
       " (3, 0.3333333333333333),\n",
       " (4, 0.3333333333333333),\n",
       " (5, 0.3333333333333333),\n",
       " (6, 0.3333333333333333),\n",
       " (7, 0.3333333333333333),\n",
       " (8, 0.3333333333333333)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import NormModel\n",
    "\n",
    "norm_model = NormModel(doc_term_matrix, norm='l2')\n",
    "norm_model[doc_term_matrix[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
