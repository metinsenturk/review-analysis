{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alias</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>dataPublished</th>\n",
       "      <th>description</th>\n",
       "      <th>author</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>chr_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_content</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_tokens_doc</th>\n",
       "      <th>norm_tokens_doc</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>norm_tokens</th>\n",
       "      <th>sent_topics</th>\n",
       "      <th>topic_mode</th>\n",
       "      <th>topic_list</th>\n",
       "      <th>svm_classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>I stumbled across this great restaurant overlo...</td>\n",
       "      <td>Bella L.</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>11</td>\n",
       "      <td>664</td>\n",
       "      <td>4.022222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674074</td>\n",
       "      <td>['I stumbled across this great restaurant over...</td>\n",
       "      <td>[('I', 'stumbled', 'across', 'this', 'great', ...</td>\n",
       "      <td>[('stumbl', 'across', 'great', 'restaur', 'ove...</td>\n",
       "      <td>['I', 'stumbled', 'across', 'this', 'great', '...</td>\n",
       "      <td>['stumbl', 'across', 'great', 'restaur', 'over...</td>\n",
       "      <td>[(5, 0.3112545907497406), (5, 0.20203207433223...</td>\n",
       "      <td>5</td>\n",
       "      <td>5,5,9,5,3,4,5,5,5,9,5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>Excellent view on the ocean at sunset.\\nExcell...</td>\n",
       "      <td>Rachou A.</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>160</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>['Excellent view on the ocean at sunset.', 'Ex...</td>\n",
       "      <td>[('Excellent', 'view', 'on', 'the', 'ocean', '...</td>\n",
       "      <td>[('excel', 'view', 'ocean', 'sunset'), ('excel...</td>\n",
       "      <td>['Excellent', 'view', 'on', 'the', 'ocean', 'a...</td>\n",
       "      <td>['excel', 'view', 'ocean', 'sunset', 'excel', ...</td>\n",
       "      <td>[(5, 0.24188750982284546), (5, 0.1962578445672...</td>\n",
       "      <td>5</td>\n",
       "      <td>5,5,3,5,5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-12-25</td>\n",
       "      <td>This place was not what the reviews portrayed ...</td>\n",
       "      <td>Ozzetta B.</td>\n",
       "      <td>0</td>\n",
       "      <td>275</td>\n",
       "      <td>14</td>\n",
       "      <td>1229</td>\n",
       "      <td>3.596364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567273</td>\n",
       "      <td>['This place was not what the reviews portraye...</td>\n",
       "      <td>[('This', 'place', 'was', 'not', 'what', 'the'...</td>\n",
       "      <td>[('place', 'review', 'portray'), ('starter', '...</td>\n",
       "      <td>['This', 'place', 'was', 'not', 'what', 'the',...</td>\n",
       "      <td>['place', 'review', 'portray', 'starter', 'wal...</td>\n",
       "      <td>[(5, 0.19056889414787292), (5, 0.2658553421497...</td>\n",
       "      <td>5</td>\n",
       "      <td>5,5,1,1,1,7,5,5,5,0,5,5,2,5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-08</td>\n",
       "      <td>We were excited to repeat our Keoki's (in Kaua...</td>\n",
       "      <td>Arleen C.</td>\n",
       "      <td>0</td>\n",
       "      <td>475</td>\n",
       "      <td>34</td>\n",
       "      <td>2226</td>\n",
       "      <td>3.783158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604211</td>\n",
       "      <td>[\"We were excited to repeat our Keoki's (in Ka...</td>\n",
       "      <td>[('We', 'were', 'excited', 'to', 'repeat', 'ou...</td>\n",
       "      <td>[('excit', 'repeat', 'keoki', \"'s\", 'kauai', '...</td>\n",
       "      <td>['We', 'were', 'excited', 'to', 'repeat', 'our...</td>\n",
       "      <td>['excit', 'repeat', 'keoki', \"'s\", 'kauai', 'l...</td>\n",
       "      <td>[(5, 0.18351130187511444), (5, 0.2023473381996...</td>\n",
       "      <td>5</td>\n",
       "      <td>5,5,2,6,5,0,5,5,8,5,5,5,7,7,5,5,5,5,5,5,5,7,9,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kimos-maui-lahaina</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>If you're looking for a tourist spot, this is ...</td>\n",
       "      <td>Carol B.</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>10</td>\n",
       "      <td>776</td>\n",
       "      <td>3.732143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636905</td>\n",
       "      <td>[\"If you're looking for a tourist spot, this i...</td>\n",
       "      <td>[('If', 'you', \"'re\", 'looking', 'for', 'a', '...</td>\n",
       "      <td>[(\"'re\", 'look', 'tourist', 'spot'), ('unfortu...</td>\n",
       "      <td>['If', 'you', \"'re\", 'looking', 'for', 'a', 't...</td>\n",
       "      <td>[\"'re\", 'look', 'tourist', 'spot', 'unfortun',...</td>\n",
       "      <td>[(5, 0.21350185573101044), (5, 0.1800063550472...</td>\n",
       "      <td>5</td>\n",
       "      <td>5,5,2,6,9,5,9,0,5,5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                alias  ratingValue dataPublished  \\\n",
       "0  kimos-maui-lahaina            5    2019-01-06   \n",
       "1  kimos-maui-lahaina            5    2019-01-04   \n",
       "2  kimos-maui-lahaina            3    2018-12-25   \n",
       "3  kimos-maui-lahaina            2    2018-12-08   \n",
       "4  kimos-maui-lahaina            3    2018-11-29   \n",
       "\n",
       "                                         description      author  sentiment  \\\n",
       "0  I stumbled across this great restaurant overlo...    Bella L.          1   \n",
       "1  Excellent view on the ocean at sunset.\\nExcell...   Rachou A.          1   \n",
       "2  This place was not what the reviews portrayed ...  Ozzetta B.          0   \n",
       "3  We were excited to repeat our Keoki's (in Kaua...   Arleen C.          0   \n",
       "4  If you're looking for a tourist spot, this is ...    Carol B.          0   \n",
       "\n",
       "   word_count  sent_count  chr_count  avg_word_len       ...        \\\n",
       "0         135          11        664      4.022222       ...         \n",
       "1          36           5        160      3.611111       ...         \n",
       "2         275          14       1229      3.596364       ...         \n",
       "3         475          34       2226      3.783158       ...         \n",
       "4         168          10        776      3.732143       ...         \n",
       "\n",
       "   ratio_content                                        sent_tokens  \\\n",
       "0       0.674074  ['I stumbled across this great restaurant over...   \n",
       "1       0.638889  ['Excellent view on the ocean at sunset.', 'Ex...   \n",
       "2       0.567273  ['This place was not what the reviews portraye...   \n",
       "3       0.604211  [\"We were excited to repeat our Keoki's (in Ka...   \n",
       "4       0.636905  [\"If you're looking for a tourist spot, this i...   \n",
       "\n",
       "                                     word_tokens_doc  \\\n",
       "0  [('I', 'stumbled', 'across', 'this', 'great', ...   \n",
       "1  [('Excellent', 'view', 'on', 'the', 'ocean', '...   \n",
       "2  [('This', 'place', 'was', 'not', 'what', 'the'...   \n",
       "3  [('We', 'were', 'excited', 'to', 'repeat', 'ou...   \n",
       "4  [('If', 'you', \"'re\", 'looking', 'for', 'a', '...   \n",
       "\n",
       "                                     norm_tokens_doc  \\\n",
       "0  [('stumbl', 'across', 'great', 'restaur', 'ove...   \n",
       "1  [('excel', 'view', 'ocean', 'sunset'), ('excel...   \n",
       "2  [('place', 'review', 'portray'), ('starter', '...   \n",
       "3  [('excit', 'repeat', 'keoki', \"'s\", 'kauai', '...   \n",
       "4  [(\"'re\", 'look', 'tourist', 'spot'), ('unfortu...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  ['I', 'stumbled', 'across', 'this', 'great', '...   \n",
       "1  ['Excellent', 'view', 'on', 'the', 'ocean', 'a...   \n",
       "2  ['This', 'place', 'was', 'not', 'what', 'the',...   \n",
       "3  ['We', 'were', 'excited', 'to', 'repeat', 'our...   \n",
       "4  ['If', 'you', \"'re\", 'looking', 'for', 'a', 't...   \n",
       "\n",
       "                                         norm_tokens  \\\n",
       "0  ['stumbl', 'across', 'great', 'restaur', 'over...   \n",
       "1  ['excel', 'view', 'ocean', 'sunset', 'excel', ...   \n",
       "2  ['place', 'review', 'portray', 'starter', 'wal...   \n",
       "3  ['excit', 'repeat', 'keoki', \"'s\", 'kauai', 'l...   \n",
       "4  [\"'re\", 'look', 'tourist', 'spot', 'unfortun',...   \n",
       "\n",
       "                                         sent_topics  topic_mode  \\\n",
       "0  [(5, 0.3112545907497406), (5, 0.20203207433223...           5   \n",
       "1  [(5, 0.24188750982284546), (5, 0.1962578445672...           5   \n",
       "2  [(5, 0.19056889414787292), (5, 0.2658553421497...           5   \n",
       "3  [(5, 0.18351130187511444), (5, 0.2023473381996...           5   \n",
       "4  [(5, 0.21350185573101044), (5, 0.1800063550472...           5   \n",
       "\n",
       "                                          topic_list  svm_classifier  \n",
       "0                              5,5,9,5,3,4,5,5,5,9,5               1  \n",
       "1                                          5,5,3,5,5               1  \n",
       "2                        5,5,1,1,1,7,5,5,5,0,5,5,2,5               0  \n",
       "3  5,5,2,6,5,0,5,5,8,5,5,5,7,7,5,5,5,5,5,5,5,7,9,...               1  \n",
       "4                                5,5,2,6,9,5,9,0,5,5               1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"../../data/processed/yp_competitors_rws_0001_0256_complete.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_tokens_doc</th>\n",
       "      <th>norm_tokens_doc</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>norm_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[I stumbled across this great restaurant overl...</td>\n",
       "      <td>[(I, stumbled, across, this, great, restaurant...</td>\n",
       "      <td>[(stumbl, across, great, restaur, overlook, oc...</td>\n",
       "      <td>[I, stumbled, across, this, great, restaurant,...</td>\n",
       "      <td>[stumbl, across, great, restaur, overlook, oce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Excellent view on the ocean at sunset., Excel...</td>\n",
       "      <td>[(Excellent, view, on, the, ocean, at, sunset,...</td>\n",
       "      <td>[(excel, view, ocean, sunset), (excel, food), ...</td>\n",
       "      <td>[Excellent, view, on, the, ocean, at, sunset, ...</td>\n",
       "      <td>[excel, view, ocean, sunset, excel, food, fres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[This place was not what the reviews portrayed...</td>\n",
       "      <td>[(This, place, was, not, what, the, reviews, p...</td>\n",
       "      <td>[(place, review, portray), (starter, walk, sta...</td>\n",
       "      <td>[This, place, was, not, what, the, reviews, po...</td>\n",
       "      <td>[place, review, portray, starter, walk, stair,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[We were excited to repeat our Keoki's (in Kau...</td>\n",
       "      <td>[(We, were, excited, to, repeat, our, Keoki, '...</td>\n",
       "      <td>[(excit, repeat, keoki, 's, kauai, lovefest, s...</td>\n",
       "      <td>[We, were, excited, to, repeat, our, Keoki, 's...</td>\n",
       "      <td>[excit, repeat, keoki, 's, kauai, lovefest, si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[If you're looking for a tourist spot, this is...</td>\n",
       "      <td>[(If, you, 're, looking, for, a, tourist, spot...</td>\n",
       "      <td>[('re, look, tourist, spot), (unfortun, could,...</td>\n",
       "      <td>[If, you, 're, looking, for, a, tourist, spot,...</td>\n",
       "      <td>['re, look, tourist, spot, unfortun, could, n'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[What an amazing restaurant, especially the vi...</td>\n",
       "      <td>[(What, an, amazing, restaurant, ,, especially...</td>\n",
       "      <td>[(amaz, restaur, especi, view, dinner), (dine,...</td>\n",
       "      <td>[What, an, amazing, restaurant, ,, especially,...</td>\n",
       "      <td>[amaz, restaur, especi, view, dinner, dine, wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sent_tokens  \\\n",
       "0  [I stumbled across this great restaurant overl...   \n",
       "1  [Excellent view on the ocean at sunset., Excel...   \n",
       "2  [This place was not what the reviews portrayed...   \n",
       "3  [We were excited to repeat our Keoki's (in Kau...   \n",
       "4  [If you're looking for a tourist spot, this is...   \n",
       "5  [What an amazing restaurant, especially the vi...   \n",
       "\n",
       "                                     word_tokens_doc  \\\n",
       "0  [(I, stumbled, across, this, great, restaurant...   \n",
       "1  [(Excellent, view, on, the, ocean, at, sunset,...   \n",
       "2  [(This, place, was, not, what, the, reviews, p...   \n",
       "3  [(We, were, excited, to, repeat, our, Keoki, '...   \n",
       "4  [(If, you, 're, looking, for, a, tourist, spot...   \n",
       "5  [(What, an, amazing, restaurant, ,, especially...   \n",
       "\n",
       "                                     norm_tokens_doc  \\\n",
       "0  [(stumbl, across, great, restaur, overlook, oc...   \n",
       "1  [(excel, view, ocean, sunset), (excel, food), ...   \n",
       "2  [(place, review, portray), (starter, walk, sta...   \n",
       "3  [(excit, repeat, keoki, 's, kauai, lovefest, s...   \n",
       "4  [('re, look, tourist, spot), (unfortun, could,...   \n",
       "5  [(amaz, restaur, especi, view, dinner), (dine,...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  [I, stumbled, across, this, great, restaurant,...   \n",
       "1  [Excellent, view, on, the, ocean, at, sunset, ...   \n",
       "2  [This, place, was, not, what, the, reviews, po...   \n",
       "3  [We, were, excited, to, repeat, our, Keoki, 's...   \n",
       "4  [If, you, 're, looking, for, a, tourist, spot,...   \n",
       "5  [What, an, amazing, restaurant, ,, especially,...   \n",
       "\n",
       "                                         norm_tokens  \n",
       "0  [stumbl, across, great, restaur, overlook, oce...  \n",
       "1  [excel, view, ocean, sunset, excel, food, fres...  \n",
       "2  [place, review, portray, starter, walk, stair,...  \n",
       "3  [excit, repeat, keoki, 's, kauai, lovefest, si...  \n",
       "4  ['re, look, tourist, spot, unfortun, could, n'...  \n",
       "5  [amaz, restaur, especi, view, dinner, dine, wa...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix column type error\n",
    "from ast import literal_eval\n",
    "\n",
    "fix_columns_list = ['sent_tokens', 'word_tokens_doc', 'norm_tokens_doc', 'word_tokens', 'norm_tokens']\n",
    "for column in fix_columns_list:\n",
    "    df[column] = df[column].apply(lambda x: literal_eval(x))\n",
    "df.loc[:5, fix_columns_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<itertools.chain at 0x11a98d6a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "chain(*df.norm_tokens[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "data = pd.Series(list(chain(*df.norm_tokens_doc[:100])), name='norm_tokens_doc')\n",
    "data = list(chain(*df.norm_tokens_doc[:100]))\n",
    "\n",
    "id2word = Dictionary(documents=data)\n",
    "doc_term_matrix = [id2word.doc2bow(doc) for doc in data]\n",
    "doc_term_matrix[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('stumbl',\n",
       " 'across',\n",
       " 'great',\n",
       " 'restaur',\n",
       " 'overlook',\n",
       " 'ocean',\n",
       " 'lunch',\n",
       " 'vacat',\n",
       " 'maui')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00866161, 0.01037352, 0.00901465, 0.00861813, 0.01091012,\n",
       "        0.00675563, 0.00811255, 0.00747221, 0.00783237, 0.00902879,\n",
       "        0.00808466, 0.00825698, 0.00857931, 0.00767344, 0.01042957,\n",
       "        0.00575921, 0.0085231 , 0.00866897, 0.0087448 , 0.00822982,\n",
       "        0.00857332, 0.00707869, 0.00672183, 0.00665621, 0.00735808,\n",
       "        0.00756973, 0.00683206, 0.00863217, 0.00784819, 0.0086639 ,\n",
       "        0.00610754, 0.00778942, 0.00718813, 0.00651299, 0.00853479,\n",
       "        0.00769129, 0.00884472, 0.0072609 , 0.00693919, 0.00662968,\n",
       "        0.0086499 , 0.00702826, 0.00734878, 0.00650565, 0.00822331,\n",
       "        0.00755283, 0.00730387, 0.00724072, 0.008452  , 0.00680944,\n",
       "        0.00716249, 0.00691178, 0.00861371, 0.00712514, 0.00768382,\n",
       "        0.00704734, 0.00648599, 0.00619168, 0.00755612, 0.00807397,\n",
       "        0.00754726, 0.0055869 , 0.00718995, 0.00711303, 0.00628609,\n",
       "        0.00778754, 0.00673007, 0.00722086, 0.00670699, 0.00594004,\n",
       "        0.00743828, 0.00760643, 0.00631073, 0.00645192, 0.00683298,\n",
       "        0.00893364, 0.0080905 , 0.00692393, 0.00823864, 0.00627155,\n",
       "        0.00745104, 0.0065969 , 0.0079424 , 0.00785602, 0.00670982,\n",
       "        0.00676786, 0.00743524, 0.00609169, 0.00661052, 0.00679035,\n",
       "        0.00701609, 0.0069869 , 0.00770086, 0.00845879, 0.00768823,\n",
       "        0.00760292, 0.00783159, 0.00699029, 0.00674948, 0.00721612,\n",
       "        0.00562059, 0.00542493, 0.00648411, 0.00545042, 0.00646477,\n",
       "        0.00591463, 0.00702213, 0.00687266, 0.00597117, 0.00674441,\n",
       "        0.00722768, 0.00526793, 0.00567748, 0.00598395, 0.00495519,\n",
       "        0.00535913, 0.00571097, 0.00506229, 0.00608131, 0.00622925,\n",
       "        0.00526967, 0.00511943, 0.00561337, 0.00394156, 0.00470789,\n",
       "        0.00501709, 0.00401289, 0.00568971, 0.00445718, 0.00519396,\n",
       "        0.00622062, 0.00511285, 0.00448412, 0.00414743, 0.00436007,\n",
       "        0.00382459, 0.00413624, 0.00414348, 0.00365948, 0.00354059,\n",
       "        0.00402829, 0.00418097, 0.00382173, 0.00347852, 0.00325131,\n",
       "        0.00312528, 0.0035957 , 0.00334299, 0.0030752 , 0.00309329]),\n",
       " array([[1.06604969e-04, 4.71114830e-04, 8.67569861e-04, ...,\n",
       "         4.80492526e-04, 5.89637973e-05, 5.75379943e-04],\n",
       "        [1.03261067e-03, 5.04865935e-04, 5.48555964e-04, ...,\n",
       "         3.07640525e-04, 1.13675299e-04, 2.40460873e-04],\n",
       "        [6.44575893e-04, 1.91680520e-03, 1.78892796e-04, ...,\n",
       "         6.82579444e-04, 1.24210975e-03, 1.98704421e-04],\n",
       "        ...,\n",
       "        [1.04833045e-04, 3.23295544e-03, 7.12028130e-04, ...,\n",
       "         2.17118093e-04, 1.16690447e-05, 8.30738740e-05],\n",
       "        [1.47653703e-04, 4.68356900e-04, 3.62696367e-04, ...,\n",
       "         5.09889904e-04, 3.47859909e-04, 5.57360324e-04],\n",
       "        [1.34760653e-03, 2.65241757e-05, 3.04605626e-04, ...,\n",
       "         6.20530456e-04, 9.26279749e-04, 2.97172966e-04]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import HdpModel\n",
    "\n",
    "hdp_model = HdpModel(doc_term_matrix, id2word)\n",
    "hdp_model.show_topics(num_words=4, num_topics=3)\n",
    "hdp_model.()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(63, 0.9007643217671838)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_list = hdp_model[doc_term_matrix[0]]\n",
    "max(doc_topic_list, key=lambda x: x[1])\n",
    "doc_topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(63, 0.9007643217671838)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.522*\"\\'s\" + 0.326*\"kimo\" + 0.215*\"fish\" + 0.210*\"view\"'),\n",
       " (1, '-0.549*\"\\'s\" + -0.347*\"kimo\" + 0.345*\"view\" + 0.220*\"fish\"'),\n",
       " (2, '0.590*\"fish\" + -0.365*\"view\" + 0.284*\"mahi\" + 0.266*\"order\"')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import LsiModel\n",
    "lsi_model = LsiModel(corpus=doc_term_matrix, num_topics=10, id2word=id2word)\n",
    "lsi_model.show_topics(num_words=4, num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.4577767745022286),\n",
       " (1, -0.3394702397301862),\n",
       " (2, 0.43806532995484854),\n",
       " (3, -0.24163345759488503),\n",
       " (4, 0.12888575129368146),\n",
       " (5, -0.11204414833687067),\n",
       " (6, -0.0816756155945271),\n",
       " (7, -0.48514348673887825),\n",
       " (8, -0.29732854727856384),\n",
       " (9, 0.7437154251852944)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_list = lsi_model[doc_term_matrix[0]]\n",
    "max(doc_topic_list, key=lambda x: x[1])\n",
    "doc_topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/text/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py:442: RuntimeWarning: invalid value encountered in true_divide\n",
      "  topic = topic / topic.sum()  # normalize to probability dist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(7, 'nan*\"1003\" + nan*\"1005\" + nan*\"1001\" + nan*\"1002\"'),\n",
       " (8, 'nan*\"1003\" + nan*\"1005\" + nan*\"1001\" + nan*\"1002\"'),\n",
       " (0, 'nan*\"1003\" + nan*\"1005\" + nan*\"1001\" + nan*\"1002\"')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.wrappers import LdaMallet\n",
    "\n",
    "mallet_path = '../../model/mallet-2.0.8/bin/mallet'\n",
    "lda_mallet = LdaMallet(mallet_path, doc_term_matrix, num_topics=10)\n",
    "lda_mallet.show_topics(num_words=4, num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LdaMallet == type(lda_mallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 0.125)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_list = lda_mallet[doc_term_matrix][1]\n",
    "doc_topic_list\n",
    "max(doc_topic_list, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.035*\"\\'s\" + 0.016*\"kimo\" + 0.010*\"fish\" + 0.008*\"go\"'),\n",
       " (5, '0.017*\"\\'s\" + 0.014*\"fish\" + 0.014*\"good\" + 0.011*\"got\"'),\n",
       " (3, '0.022*\"\\'s\" + 0.016*\"pie\" + 0.015*\"fish\" + 0.015*\"hula\"')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import LdaModel\n",
    "lda_model = LdaModel(corpus=doc_term_matrix, id2word=id2word, num_topics=10)\n",
    "[i for i in lda_model[doc_term_matrix[0:1]]]\n",
    "lda_model.show_topics(num_words=4, num_topics=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '-0.626*\"lunch\" + -0.494*\"stumbl\" + 0.361*\"maui\" + 0.334*\"across\"'),\n",
       " (1, '0.638*\"ocean\" + 0.481*\"restaur\" + -0.380*\"maui\" + -0.236*\"across\"'),\n",
       " (2, '-0.634*\"vacat\" + 0.560*\"maui\" + -0.330*\"across\" + 0.316*\"stumbl\"')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import RpModel\n",
    "\n",
    "# transformation like\n",
    "rp_model = RpModel(doc_term_matrix, id2word, num_topics=10)\n",
    "lsi_model = LsiModel(corpus=rp_model[doc_term_matrix], num_topics=10, id2word=id2word)\n",
    "lsi_model.show_topics(num_words=4, num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, '0.010*\"view\" + 0.008*\"good\" + 0.008*\"excel\" + 0.008*\"realli\"'),\n",
       " (8, '0.012*\"hula\" + 0.011*\"pie\" + 0.008*\"great\" + 0.007*\"get\"'),\n",
       " (2, '0.007*\"definit\" + 0.007*\"back\" + 0.007*\"view\" + 0.006*\"visit\"')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import TfidfModel\n",
    "\n",
    "# transformation like\n",
    "tfidf_model = TfidfModel(id2word=id2word, corpus=doc_term_matrix)\n",
    "tfidf_model[doc_term_matrix[0]]\n",
    "lda_model = LdaModel(corpus=tfidf_model[doc_term_matrix], id2word=id2word, num_topics=10)\n",
    "lda_model.show_topics(num_words=4, num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, '0.014*\"drink\" + 0.013*\"\\'s\" + 0.009*\"fish\" + 0.008*\"better\"'),\n",
       " (6, '0.017*\"food\" + 0.011*\"\\'s\" + 0.008*\"realli\" + 0.008*\"servic\"'),\n",
       " (4, '0.023*\"view\" + 0.014*\"would\" + 0.012*\"fish\" + 0.011*\"good\"')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import NormModel\n",
    "\n",
    "norm_model = NormModel(doc_term_matrix, norm='l2')\n",
    "\n",
    "doc_term_matrix = [norm_model[id2word.doc2bow(doc)] for doc in data]\n",
    "lda_model = LdaModel(corpus=doc_term_matrix, id2word=id2word, num_topics=10)\n",
    "lda_model.show_topics(num_words=4, num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '-0.360*\"view\" + -0.350*\"food\" + -0.272*\"great\" + -0.222*\"good\"'),\n",
       " (1, '0.503*\"food\" + 0.444*\"delici\" + 0.359*\"good\" + -0.308*\"view\"'),\n",
       " (2, '0.522*\"view\" + -0.265*\"\\'s\" + -0.253*\"pie\" + -0.248*\"hula\"')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import LogEntropyModel\n",
    "log_model = LogEntropyModel(doc_term_matrix)\n",
    "lsi_model = LsiModel(corpus=log_model[doc_term_matrix], num_topics=10, id2word=id2word)\n",
    "lsi_model.show_topics(num_words=4, num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
