{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"../../data/processed/hi_rws_0001_0256_descriptive.csv\"\n",
    "df = pd.read_csv(file_path, nrows=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous Preprocessing Steps\n",
    "\n",
    "1. Sent Tokens\n",
    "2. Word Tokens\n",
    "3. Remove punctuations \n",
    "4. Remove stopwords (NLTK List)\n",
    "5. Lower words\n",
    "6. Lemmatize\n",
    "7. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 21 columns):\n",
      "alias               1000 non-null object\n",
      "ratingValue         1000 non-null int64\n",
      "dataPublished       1000 non-null object\n",
      "description         1000 non-null object\n",
      "author              1000 non-null object\n",
      "sentiment           1000 non-null int64\n",
      "word_count          1000 non-null int64\n",
      "sent_count          1000 non-null int64\n",
      "chr_count           1000 non-null int64\n",
      "avg_word_len        1000 non-null float64\n",
      "avg_sent_len        1000 non-null float64\n",
      "num_of_stopwords    1000 non-null int64\n",
      "num_of_modals       1000 non-null int64\n",
      "hashtags            1000 non-null int64\n",
      "mentions            1000 non-null int64\n",
      "numerics            1000 non-null int64\n",
      "uppercase_cnt       1000 non-null int64\n",
      "punctuation_cnt     1000 non-null int64\n",
      "vocab_cnt           1000 non-null int64\n",
      "ratio_lexical       1000 non-null float64\n",
      "ratio_content       1000 non-null float64\n",
      "dtypes: float64(4), int64(13), object(4)\n",
      "memory usage: 164.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1185c62b0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\", disable=['ner'])\n",
    "print(spacy.__version__)\n",
    "nlp.pipe_names\n",
    "nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Testing with a Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_', '__bytes__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__pyx_vtable__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', '_bulk_merge', '_py_tokens', '_realloc', '_vector', '_vector_norm', 'cats', 'char_span', 'count_by', 'doc', 'ents', 'extend_tensor', 'from_array', 'from_bytes', 'from_disk', 'get_extension', 'get_lca_matrix', 'has_extension', 'has_vector', 'is_parsed', 'is_sentenced', 'is_tagged', 'mem', 'merge', 'noun_chunks', 'noun_chunks_iterator', 'print_tree', 'remove_extension', 'retokenize', 'sentiment', 'sents', 'set_extension', 'similarity', 'tensor', 'text', 'text_with_ws', 'to_array', 'to_bytes', 'to_disk', 'user_data', 'user_hooks', 'user_span_hooks', 'user_token_hooks', 'vector', 'vector_norm', 'vocab']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nlp(df.description[5])\n",
    "sent = [i for i in text.sents][0]\n",
    "print(dir(text))\n",
    "type(text[0].lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in text.noun_chunks]\n",
    "text[0].sent.text != 'I stumbled across this great my vacation to Maui.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', 'amazing', 'restaurant', 'view', 'dinner'),\n",
       " ('what', 'amazing', 'restaurant', 'view', 'dinner'),\n",
       " ('what', 'amazing', 'restaurant', 'view', 'dinner'),\n",
       " ('what', 'amazing', 'restaurant', 'view', 'dinner'),\n",
       " ('what', 'amazing', 'restaurant', 'view', 'dinner'),\n",
       " ('what', 'amazing', 'restaurant', 'view', 'dinner'),\n",
       " ('what', 'amazing', 'restaurant', 'view', 'dinner'),\n",
       " ('what', 'amazing', 'restaurant', 'view', 'dinner'),\n",
       " ('what', 'amazing', 'restaurant', 'view', 'dinner'),\n",
       " ('what', 'amazing', 'restaurant', 'view', 'dinner'),\n",
       " ('what', 'amazing', 'restaurant', 'view', 'dinner'),\n",
       " ('what', 'amazing', 'restaurant', 'view', 'dinner'),\n",
       " ('din', 'wave', 'crash', 'nice', 'relaxing'),\n",
       " ('din', 'wave', 'crash', 'nice', 'relaxing'),\n",
       " ('din', 'wave', 'crash', 'nice', 'relaxing'),\n",
       " ('din', 'wave', 'crash', 'nice', 'relaxing'),\n",
       " ('din', 'wave', 'crash', 'nice', 'relaxing'),\n",
       " ('din', 'wave', 'crash', 'nice', 'relaxing'),\n",
       " ('din', 'wave', 'crash', 'nice', 'relaxing'),\n",
       " ('din', 'wave', 'crash', 'nice', 'relaxing'),\n",
       " ('din', 'wave', 'crash', 'nice', 'relaxing'),\n",
       " ('din', 'wave', 'crash', 'nice', 'relaxing'),\n",
       " ('din', 'wave', 'crash', 'nice', 'relaxing'),\n",
       " ('din', 'wave', 'crash', 'nice', 'relaxing'),\n",
       " ('din', 'wave', 'crash', 'nice', 'relaxing'),\n",
       " ('din', 'wave', 'crash', 'nice', 'relaxing'),\n",
       " ('din', 'wave', 'crash', 'nice', 'relaxing'),\n",
       " ('food', 'good', 'start', 'avocado', 'stack', 'will', 'disappoint'),\n",
       " ('food', 'good', 'start', 'avocado', 'stack', 'will', 'disappoint'),\n",
       " ('food', 'good', 'start', 'avocado', 'stack', 'will', 'disappoint'),\n",
       " ('food', 'good', 'start', 'avocado', 'stack', 'will', 'disappoint'),\n",
       " ('food', 'good', 'start', 'avocado', 'stack', 'will', 'disappoint'),\n",
       " ('food', 'good', 'start', 'avocado', 'stack', 'will', 'disappoint'),\n",
       " ('food', 'good', 'start', 'avocado', 'stack', 'will', 'disappoint'),\n",
       " ('food', 'good', 'start', 'avocado', 'stack', 'will', 'disappoint'),\n",
       " ('food', 'good', 'start', 'avocado', 'stack', 'will', 'disappoint'),\n",
       " ('food', 'good', 'start', 'avocado', 'stack', 'will', 'disappoint'),\n",
       " ('food', 'good', 'start', 'avocado', 'stack', 'will', 'disappoint'),\n",
       " ('food', 'good', 'start', 'avocado', 'stack', 'will', 'disappoint'),\n",
       " ('food', 'good', 'start', 'avocado', 'stack', 'will', 'disappoint'),\n",
       " ('food', 'good', 'start', 'avocado', 'stack', 'will', 'disappoint'),\n",
       " ('food', 'good', 'start', 'avocado', 'stack', 'will', 'disappoint'),\n",
       " ('food', 'good', 'start', 'avocado', 'stack', 'will', 'disappoint'),\n",
       " ('food', 'good', 'start', 'avocado', 'stack', 'will', 'disappoint'),\n",
       " ('food', 'good', 'start', 'avocado', 'stack', 'will', 'disappoint'),\n",
       " ('food', 'good', 'start', 'avocado', 'stack', 'will', 'disappoint'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('order',\n",
       "  'steak',\n",
       "  'lobster',\n",
       "  'will',\n",
       "  'notice',\n",
       "  'lobster',\n",
       "  'tail',\n",
       "  'seasoning',\n",
       "  'that',\n",
       "  'come',\n",
       "  'charred',\n",
       "  'what',\n",
       "  'great',\n",
       "  'taste'),\n",
       " ('forget', 'must', 'hula'),\n",
       " ('forget', 'must', 'hula'),\n",
       " ('forget', 'must', 'hula'),\n",
       " ('forget', 'must', 'hula'),\n",
       " ('forget', 'must', 'hula'),\n",
       " ('forget', 'must', 'hula'),\n",
       " ('forget', 'must', 'hula'),\n",
       " ('forget', 'must', 'hula'),\n",
       " ('forget', 'must', 'hula'),\n",
       " ('forget', 'must', 'hula'),\n",
       " ('forget', 'must', 'hula'),\n",
       " ('forget', 'must', 'hula'),\n",
       " ('forget', 'must', 'hula'),\n",
       " ('forget', 'must', 'hula'),\n",
       " ('pricey', 'have', 'people', 'average', 'bill', 'come'),\n",
       " ('pricey', 'have', 'people', 'average', 'bill', 'come'),\n",
       " ('pricey', 'have', 'people', 'average', 'bill', 'come'),\n",
       " ('pricey', 'have', 'people', 'average', 'bill', 'come'),\n",
       " ('pricey', 'have', 'people', 'average', 'bill', 'come'),\n",
       " ('pricey', 'have', 'people', 'average', 'bill', 'come'),\n",
       " ('pricey', 'have', 'people', 'average', 'bill', 'come'),\n",
       " ('pricey', 'have', 'people', 'average', 'bill', 'come'),\n",
       " ('pricey', 'have', 'people', 'average', 'bill', 'come'),\n",
       " ('pricey', 'have', 'people', 'average', 'bill', 'come'),\n",
       " ('pricey', 'have', 'people', 'average', 'bill', 'come'),\n",
       " ('pricey', 'have', 'people', 'average', 'bill', 'come'),\n",
       " ('pricey', 'have', 'people', 'average', 'bill', 'come'),\n",
       " ('pricey', 'have', 'people', 'average', 'bill', 'come'),\n",
       " ('pricey', 'have', 'people', 'average', 'bill', 'come'),\n",
       " ('pricey', 'have', 'people', 'average', 'bill', 'come'),\n",
       " ('pricey', 'have', 'people', 'average', 'bill', 'come'),\n",
       " ('pricey', 'have', 'people', 'average', 'bill', 'come')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solution one that I dont like\n",
    "texts = []\n",
    "for sent_token in text.sents:\n",
    "\n",
    "    for token in text:        \n",
    "        if token in sent_token:\n",
    "            # do cleaning in here\n",
    "            texts.append(clean_up(sent_token.text))\n",
    "[tuple(i) for i in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'amazing']\n",
      "['what', 'amazing', 'restaurant']\n",
      "['what', 'amazing', 'restaurant', 'view']\n",
      "['what', 'amazing', 'restaurant', 'view', 'dinner']\n",
      "['din']\n",
      "['din', 'wave']\n",
      "['din', 'wave', 'crash']\n",
      "['din', 'wave', 'crash', 'nice']\n",
      "['din', 'wave', 'crash', 'nice', 'relaxing']\n",
      "['food']\n",
      "['food', 'good']\n",
      "['food', 'good', 'start']\n",
      "['food', 'good', 'start', 'avocado']\n",
      "['food', 'good', 'start', 'avocado', 'stack']\n",
      "['food', 'good', 'start', 'avocado', 'stack', 'will']\n",
      "['food', 'good', 'start', 'avocado', 'stack', 'will', 'disappoint']\n",
      "['order']\n",
      "['order', 'steak']\n",
      "['order', 'steak', 'lobster']\n",
      "['order', 'steak', 'lobster', 'will']\n",
      "['order', 'steak', 'lobster', 'will', 'notice']\n",
      "['order', 'steak', 'lobster', 'will', 'notice', 'lobster']\n",
      "['order', 'steak', 'lobster', 'will', 'notice', 'lobster', 'tail']\n",
      "['order', 'steak', 'lobster', 'will', 'notice', 'lobster', 'tail', 'seasoning']\n",
      "['order', 'steak', 'lobster', 'will', 'notice', 'lobster', 'tail', 'seasoning', 'that']\n",
      "['order', 'steak', 'lobster', 'will', 'notice', 'lobster', 'tail', 'seasoning', 'that', 'come']\n",
      "['order', 'steak', 'lobster', 'will', 'notice', 'lobster', 'tail', 'seasoning', 'that', 'come', 'charred']\n",
      "['order', 'steak', 'lobster', 'will', 'notice', 'lobster', 'tail', 'seasoning', 'that', 'come', 'charred', 'what']\n",
      "['order', 'steak', 'lobster', 'will', 'notice', 'lobster', 'tail', 'seasoning', 'that', 'come', 'charred', 'what', 'great']\n",
      "['order', 'steak', 'lobster', 'will', 'notice', 'lobster', 'tail', 'seasoning', 'that', 'come', 'charred', 'what', 'great', 'taste']\n",
      "['forget']\n",
      "['forget', 'must']\n",
      "['forget', 'must', 'hula']\n",
      "['pricey']\n",
      "['pricey', 'have']\n",
      "['pricey', 'have', 'people']\n",
      "['pricey', 'have', 'people', 'average']\n",
      "['pricey', 'have', 'people', 'average', 'bill']\n",
      "['pricey', 'have', 'people', 'average', 'bill', 'come']\n",
      "6 6\n"
     ]
    }
   ],
   "source": [
    "# solution that is fair enough\n",
    "texts = []\n",
    "sent_current = \"\"\n",
    "for token in text:     \n",
    "    # check for tokens current sent\n",
    "    if sent_current == token.sent.text: \n",
    "        # add same sent tokens to the sent list\n",
    "        token_clean = token_clean_up(token)\n",
    "        if token_clean is not None:\n",
    "            sent.append(token_clean)\n",
    "            print(sent)\n",
    "    else:         \n",
    "        # add it to texts, if it is not initially\n",
    "        if sent_current != \"\":\n",
    "            texts.append(sent)\n",
    "        # update current sent index\n",
    "        sent_current = token.sent.text\n",
    "        # create sent list and add first token\n",
    "        sent = []\n",
    "        token_clean = token_clean_up(token)\n",
    "        if token_clean is not None:\n",
    "            sent.append(token_clean)\n",
    "texts.append(sent)\n",
    "print(len(list(text.sents)), len(texts))\n",
    "# [print(i) for i in text.sents]\n",
    "# [tuple(i) for i in texts]\n",
    "# [print(i, '\\n\\n', y) for i,y in zip(text.sents, texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.span.Span' object has no attribute 'is_stop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-9ca472ddedd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnoun_chunk_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoun_chunks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stop\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alpha\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mremoval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mnoun_chunk_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.span.Span' object has no attribute 'is_stop'"
     ]
    }
   ],
   "source": [
    "noun_chunk_list = []\n",
    "for token in text.noun_chunks:\n",
    "    if token.is_stop == False and token.is_alpha and len(token) > 3 and token.pos_ not in removal:\n",
    "        noun_chunk_list.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What',\n",
       " 'an',\n",
       " 'amazing',\n",
       " 'restaurant',\n",
       " ',',\n",
       " 'especially',\n",
       " 'the',\n",
       " 'view',\n",
       " 'during',\n",
       " 'dinner']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.orth_ for i in text][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing in Review DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_clean_up(token):\n",
    "    \"\"\" token cleanup. Return clean token or None. \"\"\"\n",
    "    removal=['ADV','PRON','CCONJ','PUNCT','PART','DET','ADP','SPACE']\n",
    "    if token.is_stop == False and token.is_alpha and len(token)>3 and token.pos_ not in removal:\n",
    "        lemma = token.lemma_\n",
    "        return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(text):  \n",
    "    \"\"\" clean up tokens by documents \"\"\"\n",
    "    removal = ['ADV','PRON','CCONJ','PUNCT','PART','DET','ADP','SPACE']\n",
    "    doc = nlp(text)\n",
    "    text_out = []    \n",
    "    for token in doc:\n",
    "        if token.is_stop == False and token.is_alpha and len(token)>3 and token.pos_ not in removal:\n",
    "            lemma = token.lemma_\n",
    "            text_out.append(lemma)\n",
    "    return text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up2(text, clean_up=False):\n",
    "    \"\"\" clean up tokens by sents in documents \"\"\"\n",
    "    removal=['ADV','PRON','CCONJ','PUNCT','PART','DET','ADP','SPACE']\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    texts = []\n",
    "    sent_current = \"\"\n",
    "    for token in doc:    \n",
    "        # check for tokens current sent\n",
    "        if sent_current != token.sent.text:\n",
    "            # add it to texts, if it is not initially\n",
    "            if sent_current != \"\":\n",
    "                if len(sent) > 0:\n",
    "                    texts.append(sent)\n",
    "            # update current sent index\n",
    "            sent_current = token.sent.text\n",
    "            # create sent list and add first token\n",
    "            sent = []\n",
    "            if clean_up:\n",
    "                token_clean = token_clean_up(token)\n",
    "                if token_clean is not None:\n",
    "                    sent.append(token_clean)\n",
    "            else:\n",
    "                sent.append(token)\n",
    "        else:        \n",
    "            # add same sent tokens to the sent list\n",
    "            if clean_up:\n",
    "                token_clean = token_clean_up(token)\n",
    "                if token_clean is not None:\n",
    "                    sent.append(token_clean)\n",
    "            else:\n",
    "                sent.append(token)\n",
    "    # add the last sentence to the list\n",
    "    texts.append(sent)\n",
    "    \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df.description.apply(lambda x: clean_up2(x, True))\n",
    "type(df_test[0][0][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 8088\n"
     ]
    }
   ],
   "source": [
    "print(len(df.description), sum(len(i) for i in df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3210"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing with gensim\n",
    "from itertools import chain\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "dictionary = Dictionary(chain(*df_test))\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
