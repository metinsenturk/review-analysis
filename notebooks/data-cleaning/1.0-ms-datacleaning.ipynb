{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic text pre-processing\n",
    "\n",
    "The following basic preprocessing will be examined in this notebook. A similar example for this study can be found at [Analytics Vidhya's Website](https://www.analyticsvidhya.com/blog/2018/02/the-different-methods-deal-text-data-predictive-python/).\n",
    "\n",
    "- Lower casing\n",
    "- Punctuation removal\n",
    "- Stopwords removal\n",
    "- Frequent words removal\n",
    "- Rare words removal\n",
    "- Spelling correction\n",
    "- Tokenization\n",
    "- Stemming\n",
    "- Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "from nltk.stem import PorterStemmer\n",
    "try:\n",
    "    from nltk.corpus import stopwords\n",
    "except:\n",
    "    nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>datePublished</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Giorgio C.</td>\n",
       "      <td>2018-10-13</td>\n",
       "      <td>Try good service, beach front so a bit loud. M...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maxx C.</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>When we arrived they gave us a choice of eatin...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Al D.</td>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>Stopped in here on a Tuesday evening around 8p...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zachary D.</td>\n",
       "      <td>2018-09-29</td>\n",
       "      <td>Hawaiian chain type restaurant with pretty dec...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chilly P.</td>\n",
       "      <td>2018-07-10</td>\n",
       "      <td>Oh my. Where do I even begin...\\n\\nLet's start...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author datePublished  \\\n",
       "0  Giorgio C.    2018-10-13   \n",
       "1     Maxx C.    2018-10-05   \n",
       "2       Al D.    2018-10-04   \n",
       "3  Zachary D.    2018-09-29   \n",
       "4   Chilly P.    2018-07-10   \n",
       "\n",
       "                                         description  ratingValue  \n",
       "0  Try good service, beach front so a bit loud. M...            4  \n",
       "1  When we arrived they gave us a choice of eatin...            5  \n",
       "2  Stopped in here on a Tuesday evening around 8p...            4  \n",
       "3  Hawaiian chain type restaurant with pretty dec...            4  \n",
       "4  Oh my. Where do I even begin...\\n\\nLet's start...            1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data imports\n",
    "json_data = {}\n",
    "\n",
    "with open('../../data/raw/yp_leilanis-lahaina-2_rws.json') as f:\n",
    "    json_data = json.loads(f.read())\n",
    "\n",
    "dataset = json_normalize(json_data['reviews'])\n",
    "dataset.head()\n",
    "\n",
    "lines = dataset.iloc[:,2].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_line(line):\n",
    "    line_arr = [x.lower() for x in line.split()]\n",
    "    return(' '.join(line_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_line(line):\n",
    "    line.replace(\"[^a-zA-Z#]\", \" \")\n",
    "    line.replace('[^\\w\\s]','')\n",
    "    return(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortwords_line(line):\n",
    "    # line.apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n",
    "    return (' '.join([w for w in line.split() if len(w)>2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_line(line):\n",
    "    stopwords_list = set(stopwords.words('english'))\n",
    "    line = ' '.join(x for x in line.split() if x not in stopwords_list)\n",
    "    return(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequent Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pd.Series(' '.join(lines)).value_counts()[:10]\n",
    "freq = list(freq.index)\n",
    "\n",
    "def freqwords_line(line):\n",
    "    line = \" \".join(x for x in line.split() if x not in freq)\n",
    "    return(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rare Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare = pd.Series(' '.join(lines)).value_counts()[-10:]\n",
    "\n",
    "def rarewords_line(line):\n",
    "    line = \" \".join(x for x in line.split() if x not in rare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spellcheck_line(line):\n",
    "    return(str(TextBlob(line).correct()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_line(line):\n",
    "    return(\" \".join(TextBlob(str(line)).words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = PorterStemmer()\n",
    "def stemming_line(line):\n",
    "    line = \" \".join([st.stem(word) for word in line.split()])\n",
    "    return(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemnatize_line(line):\n",
    "    line = \" \".join([Word(word).lemmatize() for word in line.split()])\n",
    "    return(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Implementation on sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tokenize\n",
    "lines_arr = []\n",
    "for line in lines:\n",
    "    # lower\n",
    "    line = lower_line(line)\n",
    "    # punctuation\n",
    "    line = punctuation_line(line)\n",
    "    # stopwords\n",
    "    line = stopwords_line(line)\n",
    "    # freq\n",
    "    line = freqwords_line(line)\n",
    "    # shortwords\n",
    "    line = shortwords_line(line)\n",
    "    # rare\n",
    "    # line = rarewords_line(line)\n",
    "    # spelling\n",
    "    # line = spelling_line(line)\n",
    "    # tokenize\n",
    "    line = tokenize_line(line)\n",
    "    # stemming\n",
    "    line = stemming_line(line)\n",
    "    # lemmatization\n",
    "    line = lemnatize_line(line)\n",
    "    \n",
    "    lines_arr.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped in here on a Tuesday evening around 8pm and didn't have a problem getting a table for two on the patio. Menu is a bit higher priced than I think it should be but still less than most of the hotel restaurants so not too much of a rip off. I ended up getting the fish tacos which were pretty good. The server we had was friendly and fast, and we enjoyed sitting and watching the sunset. \n",
      "\n",
      "This is a solid spot if you're looking for a simple menu and don't want to dine in at the hotel restaurants.\n",
      "--------\n",
      "stop tuesday even around 8pm problem get tabl two patio menu bit higher price think still le hotel restaur much rip off end get fish taco pretti good server friendli fast enjoy sit watch sunset solid spot look simpl menu want dine hotel restaur\n"
     ]
    }
   ],
   "source": [
    "print(lines[2])\n",
    "print('--------')\n",
    "print(lines_arr[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
