{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic text pre-processing\n",
    "\n",
    "The following basic preprocessing will be examined in this notebook. A similar example for this study can be found at [Analytics Vidhya's Website](https://www.analyticsvidhya.com/blog/2018/02/the-different-methods-deal-text-data-predictive-python/).\n",
    "\n",
    "- Lower casing\n",
    "- Punctuation removal\n",
    "- Stopwords removal\n",
    "- Frequent words removal\n",
    "- Rare words removal\n",
    "- Spelling correction\n",
    "- Tokenization\n",
    "- Stemming\n",
    "- Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "from nltk.stem import PorterStemmer\n",
    "try:\n",
    "    from nltk.corpus import stopwords\n",
    "except:\n",
    "    nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Try good service, beach front so a bit loud. M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>When we arrived they gave us a choice of eatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Stopped in here on a Tuesday evening around 8p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Hawaiian chain type restaurant with pretty dec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Oh my. Where do I even begin...\\n\\nLet's start...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   status                                            reviews\n",
       "0       1  Try good service, beach front so a bit loud. M...\n",
       "1       1  When we arrived they gave us a choice of eatin...\n",
       "2       1  Stopped in here on a Tuesday evening around 8p...\n",
       "3       1  Hawaiian chain type restaurant with pretty dec...\n",
       "4       0  Oh my. Where do I even begin...\\n\\nLet's start..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('../../data/processed/yp_leilanis-lahaina-2_rws.csv')\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Try good service, beach front so a bit loud. M...\n",
       "1    When we arrived they gave us a choice of eatin...\n",
       "2    Stopped in here on a Tuesday evening around 8p...\n",
       "3    Hawaiian chain type restaurant with pretty dec...\n",
       "4    Oh my. Where do I even begin...\\n\\nLet's start...\n",
       "Name: reviews, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = dataset.iloc[:,1]\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_line(line):\n",
    "    line_arr = [x.lower() for x in line.split()]\n",
    "    return(' '.join(line_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_line(line):\n",
    "    line = line.replace(\"[^a-zA-Z#]\", \" \")\n",
    "    # line = line.replace('[^\\w\\s]','')\n",
    "    return(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortwords_line(line):\n",
    "    # line.apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n",
    "    return (' '.join([w for w in line.split() if len(w)>2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_line(line):\n",
    "    stopwords_list = set(stopwords.words('english'))\n",
    "    line = ' '.join(x for x in line.split() if x not in stopwords_list)\n",
    "    return(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequent Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pd.Series(' '.join(lines).split()).value_counts()[:10]\n",
    "\n",
    "freq = list(freq.index)\n",
    "\n",
    "def freqwords_line(line):\n",
    "    line = \" \".join(x for x in line.split() if x not in freq)\n",
    "    return(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rare Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare = pd.Series(' '.join(lines).split()).value_counts()[-10:]\n",
    "\n",
    "rare = list(rare.index)\n",
    "\n",
    "def rarewords_line(line):\n",
    "    line = \" \".join(x for x in line.split() if x not in rare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def spellcheck_line(line):\n",
    "        return(str(TextBlob(line).correct()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_line(line):\n",
    "    return(\" \".join(TextBlob(str(line)).words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = PorterStemmer()\n",
    "def stemming_line(line):\n",
    "    line = \" \".join([st.stem(word) for word in line.split()])\n",
    "    return(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemnatize_line(line):\n",
    "    line = \" \".join([Word(word).lemmatize() for word in line.split()])\n",
    "    return(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Implementation on sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"start realli good crab cake ok beet salad even though idea chees minut cold entre know is wait long cold like runner took minut break forgot starv eat anyway that 's me\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "line = \"It started out really good.  Crab cakes were ok, \\\n",
    "beet salad ok even though I had no idea what the cheese was \\\n",
    "and then after 45 minutes, cold entree.  But you know how it is. \\\n",
    "You wait so long and then it's cold like the runner took his 15 minute \\\n",
    "break and forgot about you but your starving so you eat it anyways. \\\n",
    "That's how it was for me.\"\n",
    "# lower\n",
    "line = lower_line(line)\n",
    "# punctuation\n",
    "line = punctuation_line(line)\n",
    "# stopwords\n",
    "line = stopwords_line(line)\n",
    "# freq\n",
    "line = freqwords_line(line)\n",
    "# shortwords\n",
    "line = shortwords_line(line)\n",
    "# rare\n",
    "# line = rarewords_line(line)\n",
    "# spelling\n",
    "# line = spelling_line(line)\n",
    "# tokenize\n",
    "line = tokenize_line(line)\n",
    "# stemming\n",
    "line = stemming_line(line)\n",
    "# lemmatization\n",
    "line = lemnatize_line(line)\n",
    "\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "lines_arr = []\n",
    "for line in reviews:\n",
    "    # lower\n",
    "    line = lower_line(line)\n",
    "    # punctuation\n",
    "    line = punctuation_line(line)\n",
    "    # stopwords\n",
    "    line = stopwords_line(line)\n",
    "    # freq\n",
    "    line = freqwords_line(line)\n",
    "    # shortwords\n",
    "    line = shortwords_line(line)\n",
    "    # rare\n",
    "    line = rarewords_line(line)\n",
    "    # spelling\n",
    "    # line = spelling_line(line)\n",
    "    # tokenize\n",
    "    line = tokenize_line(line)\n",
    "    # stemming\n",
    "    line = stemming_line(line)\n",
    "    # lemmatization\n",
    "    line = lemnatize_line(line)\n",
    "    \n",
    "    lines_arr.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped in here on a Tuesday evening around 8pm and didn't have a problem getting a table for two on the patio. Menu is a bit higher priced than I think it should be but still less than most of the hotel restaurants so not too much of a rip off. I ended up getting the fish tacos which were pretty good. The server we had was friendly and fast, and we enjoyed sitting and watching the sunset. \n",
      "\n",
      "This is a solid spot if you're looking for a simple menu and don't want to dine in at the hotel restaurants.\n",
      "--------\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "print(lines[2])\n",
    "print('--------')\n",
    "print(lines_arr[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tri good servic beach front bit loud menu dive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>arriv gave choic eat din room patio there 's t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>stop tuesday even around 8pm problem get tabl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>hawaiian chain type restaur pretti decent food...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>my even begin let 's start posit dine fancier ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   status                                            reviews\n",
       "0       1  tri good servic beach front bit loud menu dive...\n",
       "1       1  arriv gave choic eat din room patio there 's t...\n",
       "2       1  stop tuesday even around 8pm problem get tabl ...\n",
       "3       1  hawaiian chain type restaur pretti decent food...\n",
       "4       0  my even begin let 's start posit dine fancier ..."
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['reviews'] = lines_arr\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('../../data/processed/yp_leilanis-lahaina-2_rws_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tri good servic beach front bit loud menu dive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>arriv gave choic eat din room patio there 's t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>stop tuesday even around 8pm problem get tabl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>hawaiian chain type restaur pretti decent food...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>my even begin let 's start posit dine fancier ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   status                                            reviews\n",
       "0       1  tri good servic beach front bit loud menu dive...\n",
       "1       1  arriv gave choic eat din room patio there 's t...\n",
       "2       1  stop tuesday even around 8pm problem get tabl ...\n",
       "3       1  hawaiian chain type restaur pretti decent food...\n",
       "4       0  my even begin let 's start posit dine fancier ..."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_new = pd.read_csv('../../data/processed/yp_leilanis-lahaina-2_rws_1.csv')\n",
    "dataset_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
